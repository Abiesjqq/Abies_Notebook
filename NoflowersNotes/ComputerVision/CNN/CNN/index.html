
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../Gradient_Descent/Gradient_Descent/">
      
      
        <link rel="next" href="../../RNN/RNN/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.21">
    
    
      
        <title>CNN & Training Basics - Abies's Notebook</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.2a3383ac.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/extra2.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/cursor.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/info.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/create_and_update.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/customize.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/font.css">
    
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#layers-of-cnns" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../../.." title="Abies&#39;s Notebook" class="md-header__button md-logo" aria-label="Abies's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19.19 18H24l-3.86-6H22L15 2l-2.39 3.41L17.92 13h-1.95zM16 12 9 2 2 12h1.86L0 18h7v4h4v-4h7l-3.86-6zm-3.84-2H10.5l3.84 6H3.67l3.86-6H5.84L9 5.5zm.84 9v3h4v-3z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Abies's Notebook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CNN & Training Basics
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="teal"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Abiesjqq/Abies_Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Abies_Notebook
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../.." class="md-tabs__link">
          
  
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../%E8%87%AA%E5%AD%A6%E8%AE%B0%E5%BD%95/1_index/" class="md-tabs__link">
          
  
  
    
  
  碎碎念

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../CourseNotes/note_index/" class="md-tabs__link">
          
  
  
    
  
  课程笔记

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../Noflower_index/" class="md-tabs__link">
          
  
  
    
  
  Noflower的笔记

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../AbiesNotes/Abies_index/" class="md-tabs__link">
          
  
  
    
  
  Abies的笔记

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/Diffusion/Denoising%20Diffusion%20Probabilistic%20Models/Denoising%20Diffusion%20Probabilistic%20Models/" class="md-tabs__link">
          
  
  
    
  
  论文阅读

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../snippet/links/" class="md-tabs__link">
          
  
  
    
  
  一些小玩意

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Abies&#39;s Notebook" class="md-nav__button md-logo" aria-label="Abies's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19.19 18H24l-3.86-6H22L15 2l-2.39 3.41L17.92 13h-1.95zM16 12 9 2 2 12h1.86L0 18h7v4h4v-4h7l-3.86-6zm-3.84-2H10.5l3.84 6H3.67l3.86-6H5.84L9 5.5zm.84 9v3h4v-3z"/></svg>

    </a>
    Abies's Notebook
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Abiesjqq/Abies_Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Abies_Notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../.." class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../../%E8%87%AA%E5%AD%A6%E8%AE%B0%E5%BD%95/1_index/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    碎碎念
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../../CourseNotes/note_index/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    课程笔记
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Noflower的笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Noflower的笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Noflower_index/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    扉页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Computer Vision （进行中）
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Computer Vision （进行中）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Intro%26K-NN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Intro & K-NN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Loss%20Functions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Loss Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Gradient_Descent/Gradient_Descent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradient Descent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    CNN & Training Basics
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    CNN & Training Basics
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#layers-of-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      Layers of CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Layers of CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-conv-layers" class="md-nav__link">
    <span class="md-ellipsis">
      The Conv Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalization-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Normalization Layers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normalization Layers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-norm" class="md-nav__link">
    <span class="md-ellipsis">
      Layer Norm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stochastic-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Depth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-max-pooling" class="md-nav__link">
    <span class="md-ellipsis">
      Fractional Max Pooling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Activation Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gelu" class="md-nav__link">
    <span class="md-ellipsis">
      GELU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-lus" class="md-nav__link">
    <span class="md-ellipsis">
      Other LUs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#weight-initializations" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initializations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Weight Initializations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kaiming-msra-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Kaiming / MSRA Initialization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Data Processing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tldr-for-image-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      TLDR for Image Normalization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data augmentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameter-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameter Selection
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RNN/RNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../DetectionandSegementation/DetectionandSegementation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Detection, Segmentation, Visualization, and Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../AttentionandTransformers/AttentionandTransformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention and Transformers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../VideoUnderstanding/VideoUnderstanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Video Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/%E6%95%B0%E6%A8%A1%E7%9A%84%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%E7%AC%94%E8%AE%B0/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    数模笔记
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/Lec_1/Lec_1/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    信号与系统
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/%E7%BB%AA%E8%AE%BA/%E7%BB%AA%E8%AE%BA/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    人工智能基础
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%88%86%E6%9E%90/%E5%88%86%E6%B2%BB/%E5%88%86%E6%B2%BB/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    算法设计分析
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../../AbiesNotes/Abies_index/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Abies的笔记
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../../../%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/Diffusion/Denoising%20Diffusion%20Probabilistic%20Models/Denoising%20Diffusion%20Probabilistic%20Models/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    论文阅读
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../../snippet/links/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    一些小玩意
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#layers-of-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      Layers of CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Layers of CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-conv-layers" class="md-nav__link">
    <span class="md-ellipsis">
      The Conv Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalization-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Normalization Layers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normalization Layers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-norm" class="md-nav__link">
    <span class="md-ellipsis">
      Layer Norm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stochastic-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Depth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-max-pooling" class="md-nav__link">
    <span class="md-ellipsis">
      Fractional Max Pooling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Activation Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gelu" class="md-nav__link">
    <span class="md-ellipsis">
      GELU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-lus" class="md-nav__link">
    <span class="md-ellipsis">
      Other LUs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#weight-initializations" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initializations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Weight Initializations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kaiming-msra-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Kaiming / MSRA Initialization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Data Processing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tldr-for-image-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      TLDR for Image Normalization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data augmentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameter-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameter Selection
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>CNN & Training Basics</h1>

<div class="admonition info reading-info">
<p class="admonition-title">阅读信息</p>
<p><span class="twemoji"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8V2m6.78 1a.69.69 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38-2.5-2.5Z"></path></svg></span> 约 <strong>0</strong> 个字&nbsp;&nbsp;<strong>14</strong> 分钟&nbsp;&nbsp;本页总访问量：<span id="busuanzi_value_page_pv">加载中...</span> 次</p>
</div>
<h2 id="layers-of-cnns">Layers of CNNs</h2>
<h3 id="the-conv-layers">The Conv Layers</h3>
<ul>
<li>Accepts a volume of size <span class="arithmatex">\(W_1 \times H_1 \times D_1\)</span></li>
<li>Requires four hyperparameters:<ul>
<li>Number of filters <span class="arithmatex">\(K\)</span>,</li>
<li>their spatial extent <span class="arithmatex">\(F\)</span>,</li>
<li>the stride <span class="arithmatex">\(S\)</span>,</li>
<li>the amount of zero padding <span class="arithmatex">\(P\)</span></li>
</ul>
</li>
<li>Produces a volume of size <span class="arithmatex">\(W_2 \times H_2 \times D_2\)</span> where:<ul>
<li><span class="arithmatex">\(W_2 = \displaystyle \frac{W_1 - F + 2P}{S} + 1\)</span></li>
<li><span class="arithmatex">\(H_2 = \displaystyle \frac{H_1 - F + 2P}{S} + 1\)</span> (i.e. width and height are computed equally by symmetry)</li>
<li><span class="arithmatex">\(D_2 = K\)</span></li>
</ul>
</li>
<li>With parameter sharing, it introduces <span class="arithmatex">\(F \cdot F \cdot D_1\)</span> weights per filter, for a total of
  <span class="arithmatex">\((F \cdot F \cdot D_1) \cdot K\)</span> weights and <span class="arithmatex">\(K\)</span> biases.</li>
<li>In the output volume, the <span class="arithmatex">\(d\)</span>-th depth slice (of size <span class="arithmatex">\(W_2 \times H_2\)</span>) is the result of performing a valid convolution of the <span class="arithmatex">\(d\)</span>-th filter over the input volume with a stride of <span class="arithmatex">\(S\)</span>, and then offset by <span class="arithmatex">\(d\)</span>-th bias.</li>
</ul>
<blockquote>
<p><strong>Commonn settings</strong>:</p>
<ul>
<li><span class="arithmatex">\(K\)</span> is powers of 2
    &gt;   - <span class="arithmatex">\(F = 3, S = 1, P = 1\)</span></li>
<li><span class="arithmatex">\(F = 5, S = 1, P = 2\)</span></li>
<li><span class="arithmatex">\(F = 5, S = 2, P = \text{(Whatever fits)}\)</span></li>
<li><span class="arithmatex">\(F = 1, S = 1, P = 0\)</span></li>
</ul>
</blockquote>
<h3 id="pooling-layers">Pooling Layers</h3>
<p>(Emitted)</p>
<p>A max pooling realization here.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">Forward</label><label for="__tabbed_1_2">Backward</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">max_pool_forward_fast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="sd">    Vectorized (non-naive) version of the forward pass for a max-pooling layer.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    - x: Input data, shape (N, C, H, W)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    - pool_param: dict with keys:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">        - &#39;pool_height&#39;: int</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        - &#39;pool_width&#39;: int</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        - &#39;stride&#39;: int</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    - out: Output data, shape (N, C, H&#39;, W&#39;)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    - cache: (x, pool_param)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">ph</span><span class="p">,</span> <span class="n">pw</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;pool_height&#39;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;pool_width&#39;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">H_out</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">ph</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">W_out</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">pw</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="c1"># Create output tensor</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H_out</span><span class="p">,</span> <span class="n">W_out</span><span class="p">))</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="c1"># im2col: unfold pooling windows</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="n">x_reshaped</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">C</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="c1"># Create a matrix to hold all pooling windows</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span> <span class="o">*</span> <span class="n">C</span><span class="p">,</span> <span class="n">ph</span> <span class="o">*</span> <span class="n">pw</span><span class="p">,</span> <span class="n">H_out</span> <span class="o">*</span> <span class="n">W_out</span><span class="p">))</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="n">out_idx</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">H</span> <span class="o">-</span> <span class="n">ph</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">W</span> <span class="o">-</span> <span class="n">pw</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>            <span class="n">patch</span> <span class="o">=</span> <span class="n">x_reshaped</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">ph</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="n">pw</span><span class="p">]</span>  <span class="c1"># shape: (N*C, 1, ph, pw)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>            <span class="n">col</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">out_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">patch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">C</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="n">out_idx</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="c1"># Max over pooling regions</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape: (N*C, H_out*W_out)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">max_pool</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H_out</span><span class="p">,</span> <span class="n">W_out</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></td></tr></table></div>
</div>
<div class="tabbed-block">
<div class="arithmatex">\[
\text{dx}_{n, c, h, w} =
\begin{cases}
\text{dout}_{n,c,i,j}, &amp; \text{if } (h,w) = \underset{(h',w') \in \text{pool region}}{\arg\max} \, x_{n,c,h',w'} \\
0, &amp; \text{otherwise}
\end{cases}
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span>
<span class="normal"><a href="#__codelineno-1-12">12</a></span>
<span class="normal"><a href="#__codelineno-1-13">13</a></span>
<span class="normal"><a href="#__codelineno-1-14">14</a></span>
<span class="normal"><a href="#__codelineno-1-15">15</a></span>
<span class="normal"><a href="#__codelineno-1-16">16</a></span>
<span class="normal"><a href="#__codelineno-1-17">17</a></span>
<span class="normal"><a href="#__codelineno-1-18">18</a></span>
<span class="normal"><a href="#__codelineno-1-19">19</a></span>
<span class="normal"><a href="#__codelineno-1-20">20</a></span>
<span class="normal"><a href="#__codelineno-1-21">21</a></span>
<span class="normal"><a href="#__codelineno-1-22">22</a></span>
<span class="normal"><a href="#__codelineno-1-23">23</a></span>
<span class="normal"><a href="#__codelineno-1-24">24</a></span>
<span class="normal"><a href="#__codelineno-1-25">25</a></span>
<span class="normal"><a href="#__codelineno-1-26">26</a></span>
<span class="normal"><a href="#__codelineno-1-27">27</a></span>
<span class="normal"><a href="#__codelineno-1-28">28</a></span>
<span class="normal"><a href="#__codelineno-1-29">29</a></span>
<span class="normal"><a href="#__codelineno-1-30">30</a></span>
<span class="normal"><a href="#__codelineno-1-31">31</a></span>
<span class="normal"><a href="#__codelineno-1-32">32</a></span>
<span class="normal"><a href="#__codelineno-1-33">33</a></span>
<span class="normal"><a href="#__codelineno-1-34">34</a></span>
<span class="normal"><a href="#__codelineno-1-35">35</a></span>
<span class="normal"><a href="#__codelineno-1-36">36</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">max_pool_backward_fast</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="sd">    Vectorized backward pass for a max-pooling layer.</span>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="sd">    - dout: Upstream derivatives, shape (N, C, H&#39;, W&#39;)</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a><span class="sd">    - cache: Tuple of (x, pool_param) from forward pass</span>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a>
<a id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-1-10" name="__codelineno-1-10"></a><span class="sd">    - dx: Gradient with respect to x, shape same as x</span>
<a id="__codelineno-1-11" name="__codelineno-1-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-1-12" name="__codelineno-1-12"></a>    <span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span> <span class="o">=</span> <span class="n">cache</span>
<a id="__codelineno-1-13" name="__codelineno-1-13"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-1-14" name="__codelineno-1-14"></a>    <span class="n">ph</span><span class="p">,</span> <span class="n">pw</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;pool_height&#39;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;pool_width&#39;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
<a id="__codelineno-1-15" name="__codelineno-1-15"></a>    <span class="n">H_out</span><span class="p">,</span> <span class="n">W_out</span> <span class="o">=</span> <span class="n">dout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
<a id="__codelineno-1-16" name="__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17"></a>    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-1-18" name="__codelineno-1-18"></a>
<a id="__codelineno-1-19" name="__codelineno-1-19"></a>    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<a id="__codelineno-1-20" name="__codelineno-1-20"></a>        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-1-21" name="__codelineno-1-21"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">H_out</span><span class="p">):</span>
<a id="__codelineno-1-22" name="__codelineno-1-22"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">W_out</span><span class="p">):</span>
<a id="__codelineno-1-23" name="__codelineno-1-23"></a>                    <span class="n">h_start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span>
<a id="__codelineno-1-24" name="__codelineno-1-24"></a>                    <span class="n">h_end</span> <span class="o">=</span> <span class="n">h_start</span> <span class="o">+</span> <span class="n">ph</span>
<a id="__codelineno-1-25" name="__codelineno-1-25"></a>                    <span class="n">w_start</span> <span class="o">=</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span>
<a id="__codelineno-1-26" name="__codelineno-1-26"></a>                    <span class="n">w_end</span> <span class="o">=</span> <span class="n">w_start</span> <span class="o">+</span> <span class="n">pw</span>
<a id="__codelineno-1-27" name="__codelineno-1-27"></a>
<a id="__codelineno-1-28" name="__codelineno-1-28"></a>                    <span class="c1"># 当前窗口</span>
<a id="__codelineno-1-29" name="__codelineno-1-29"></a>                    <span class="n">window</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h_start</span><span class="p">:</span><span class="n">h_end</span><span class="p">,</span> <span class="n">w_start</span><span class="p">:</span><span class="n">w_end</span><span class="p">]</span>
<a id="__codelineno-1-30" name="__codelineno-1-30"></a>                    <span class="n">max_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>
<a id="__codelineno-1-31" name="__codelineno-1-31"></a>
<a id="__codelineno-1-32" name="__codelineno-1-32"></a>                    <span class="c1"># 梯度传播只传给最大值所在位置</span>
<a id="__codelineno-1-33" name="__codelineno-1-33"></a>                    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">window</span> <span class="o">==</span> <span class="n">max_val</span><span class="p">)</span>
<a id="__codelineno-1-34" name="__codelineno-1-34"></a>                    <span class="n">dx</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h_start</span><span class="p">:</span><span class="n">h_end</span><span class="p">,</span> <span class="n">w_start</span><span class="p">:</span><span class="n">w_end</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">dout</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
<a id="__codelineno-1-35" name="__codelineno-1-35"></a>
<a id="__codelineno-1-36" name="__codelineno-1-36"></a>    <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></td></tr></table></div>
</div>
</div>
</div>
<h3 id="normalization-layers">Normalization Layers</h3>
<h4 id="batch-normalization">Batch Normalization</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Forward</label><label for="__tabbed_2_2">Backward</label><label for="__tabbed_2_3">A Optimization for backward</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="arithmatex">\[
\mu = \frac{1}{m} \sum_{i=1}^{m} x_i
\quad
\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu)^2
\quad
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
\quad
y_i = \gamma \hat{x}_i + \beta
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span>
<span class="normal"><a href="#__codelineno-2-14">14</a></span>
<span class="normal"><a href="#__codelineno-2-15">15</a></span>
<span class="normal"><a href="#__codelineno-2-16">16</a></span>
<span class="normal"><a href="#__codelineno-2-17">17</a></span>
<span class="normal"><a href="#__codelineno-2-18">18</a></span>
<span class="normal"><a href="#__codelineno-2-19">19</a></span>
<span class="normal"><a href="#__codelineno-2-20">20</a></span>
<span class="normal"><a href="#__codelineno-2-21">21</a></span>
<span class="normal"><a href="#__codelineno-2-22">22</a></span>
<span class="normal"><a href="#__codelineno-2-23">23</a></span>
<span class="normal"><a href="#__codelineno-2-24">24</a></span>
<span class="normal"><a href="#__codelineno-2-25">25</a></span>
<span class="normal"><a href="#__codelineno-2-26">26</a></span>
<span class="normal"><a href="#__codelineno-2-27">27</a></span>
<span class="normal"><a href="#__codelineno-2-28">28</a></span>
<span class="normal"><a href="#__codelineno-2-29">29</a></span>
<span class="normal"><a href="#__codelineno-2-30">30</a></span>
<span class="normal"><a href="#__codelineno-2-31">31</a></span>
<span class="normal"><a href="#__codelineno-2-32">32</a></span>
<span class="normal"><a href="#__codelineno-2-33">33</a></span>
<span class="normal"><a href="#__codelineno-2-34">34</a></span>
<span class="normal"><a href="#__codelineno-2-35">35</a></span>
<span class="normal"><a href="#__codelineno-2-36">36</a></span>
<span class="normal"><a href="#__codelineno-2-37">37</a></span>
<span class="normal"><a href="#__codelineno-2-38">38</a></span>
<span class="normal"><a href="#__codelineno-2-39">39</a></span>
<span class="normal"><a href="#__codelineno-2-40">40</a></span>
<span class="normal"><a href="#__codelineno-2-41">41</a></span>
<span class="normal"><a href="#__codelineno-2-42">42</a></span>
<span class="normal"><a href="#__codelineno-2-43">43</a></span>
<span class="normal"><a href="#__codelineno-2-44">44</a></span>
<span class="normal"><a href="#__codelineno-2-45">45</a></span>
<span class="normal"><a href="#__codelineno-2-46">46</a></span>
<span class="normal"><a href="#__codelineno-2-47">47</a></span>
<span class="normal"><a href="#__codelineno-2-48">48</a></span>
<span class="normal"><a href="#__codelineno-2-49">49</a></span>
<span class="normal"><a href="#__codelineno-2-50">50</a></span>
<span class="normal"><a href="#__codelineno-2-51">51</a></span>
<span class="normal"><a href="#__codelineno-2-52">52</a></span>
<span class="normal"><a href="#__codelineno-2-53">53</a></span>
<span class="normal"><a href="#__codelineno-2-54">54</a></span>
<span class="normal"><a href="#__codelineno-2-55">55</a></span>
<span class="normal"><a href="#__codelineno-2-56">56</a></span>
<span class="normal"><a href="#__codelineno-2-57">57</a></span>
<span class="normal"><a href="#__codelineno-2-58">58</a></span>
<span class="normal"><a href="#__codelineno-2-59">59</a></span>
<span class="normal"><a href="#__codelineno-2-60">60</a></span>
<span class="normal"><a href="#__codelineno-2-61">61</a></span>
<span class="normal"><a href="#__codelineno-2-62">62</a></span>
<span class="normal"><a href="#__codelineno-2-63">63</a></span>
<span class="normal"><a href="#__codelineno-2-64">64</a></span>
<span class="normal"><a href="#__codelineno-2-65">65</a></span>
<span class="normal"><a href="#__codelineno-2-66">66</a></span>
<span class="normal"><a href="#__codelineno-2-67">67</a></span>
<span class="normal"><a href="#__codelineno-2-68">68</a></span>
<span class="normal"><a href="#__codelineno-2-69">69</a></span>
<span class="normal"><a href="#__codelineno-2-70">70</a></span>
<span class="normal"><a href="#__codelineno-2-71">71</a></span>
<span class="normal"><a href="#__codelineno-2-72">72</a></span>
<span class="normal"><a href="#__codelineno-2-73">73</a></span>
<span class="normal"><a href="#__codelineno-2-74">74</a></span>
<span class="normal"><a href="#__codelineno-2-75">75</a></span>
<span class="normal"><a href="#__codelineno-2-76">76</a></span>
<span class="normal"><a href="#__codelineno-2-77">77</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">batchnorm_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">bn_param</span><span class="p">):</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="sd">    Forward pass for batch normalization.</span>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="sd">    During training the sample mean and (uncorrected) sample variance are</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="sd">    computed from minibatch statistics and used to normalize the incoming data.</span>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="sd">    During training we also keep an exponentially decaying running mean of the</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="sd">    mean and variance of each feature, and these averages are used to normalize</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="sd">    data at test-time.</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a><span class="sd">    At each timestep we update the running averages for mean and variance using</span>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a><span class="sd">    an exponential decay based on the momentum parameter:</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a>
<a id="__codelineno-2-14" name="__codelineno-2-14"></a><span class="sd">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span>
<a id="__codelineno-2-15" name="__codelineno-2-15"></a><span class="sd">    running_var = momentum * running_var + (1 - momentum) * sample_var</span>
<a id="__codelineno-2-16" name="__codelineno-2-16"></a>
<a id="__codelineno-2-17" name="__codelineno-2-17"></a><span class="sd">    Note that the batch normalization paper suggests a different test-time</span>
<a id="__codelineno-2-18" name="__codelineno-2-18"></a><span class="sd">    behavior: they compute sample mean and variance for each feature using a</span>
<a id="__codelineno-2-19" name="__codelineno-2-19"></a><span class="sd">    large number of training images rather than using a running average. For</span>
<a id="__codelineno-2-20" name="__codelineno-2-20"></a><span class="sd">    this implementation we have chosen to use running averages instead since</span>
<a id="__codelineno-2-21" name="__codelineno-2-21"></a><span class="sd">    they do not require an additional estimation step; the torch7</span>
<a id="__codelineno-2-22" name="__codelineno-2-22"></a><span class="sd">    implementation of batch normalization also uses running averages.</span>
<a id="__codelineno-2-23" name="__codelineno-2-23"></a>
<a id="__codelineno-2-24" name="__codelineno-2-24"></a><span class="sd">    Input:</span>
<a id="__codelineno-2-25" name="__codelineno-2-25"></a><span class="sd">    - x: Data of shape (N, D)</span>
<a id="__codelineno-2-26" name="__codelineno-2-26"></a><span class="sd">    - gamma: Scale parameter of shape (D,)</span>
<a id="__codelineno-2-27" name="__codelineno-2-27"></a><span class="sd">    - beta: Shift paremeter of shape (D,)</span>
<a id="__codelineno-2-28" name="__codelineno-2-28"></a><span class="sd">    - bn_param: Dictionary with the following keys:</span>
<a id="__codelineno-2-29" name="__codelineno-2-29"></a><span class="sd">      - mode: &#39;train&#39; or &#39;test&#39;; required</span>
<a id="__codelineno-2-30" name="__codelineno-2-30"></a><span class="sd">      - eps: Constant for numeric stability</span>
<a id="__codelineno-2-31" name="__codelineno-2-31"></a><span class="sd">      - momentum: Constant for running mean / variance.</span>
<a id="__codelineno-2-32" name="__codelineno-2-32"></a><span class="sd">      - running_mean: Array of shape (D,) giving running mean of features</span>
<a id="__codelineno-2-33" name="__codelineno-2-33"></a><span class="sd">      - running_var Array of shape (D,) giving running variance of features</span>
<a id="__codelineno-2-34" name="__codelineno-2-34"></a>
<a id="__codelineno-2-35" name="__codelineno-2-35"></a><span class="sd">    Returns a tuple of:</span>
<a id="__codelineno-2-36" name="__codelineno-2-36"></a><span class="sd">    - out: of shape (N, D)</span>
<a id="__codelineno-2-37" name="__codelineno-2-37"></a><span class="sd">    - cache: A tuple of values needed in the backward pass</span>
<a id="__codelineno-2-38" name="__codelineno-2-38"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-2-39" name="__codelineno-2-39"></a>    <span class="n">mode</span> <span class="o">=</span> <span class="n">bn_param</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span>
<a id="__codelineno-2-40" name="__codelineno-2-40"></a>    <span class="n">eps</span> <span class="o">=</span> <span class="n">bn_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
<a id="__codelineno-2-41" name="__codelineno-2-41"></a>    <span class="n">momentum</span> <span class="o">=</span> <span class="n">bn_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<a id="__codelineno-2-42" name="__codelineno-2-42"></a>
<a id="__codelineno-2-43" name="__codelineno-2-43"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-2-44" name="__codelineno-2-44"></a>    <span class="n">running_mean</span> <span class="o">=</span> <span class="n">bn_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;running_mean&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<a id="__codelineno-2-45" name="__codelineno-2-45"></a>    <span class="n">running_var</span> <span class="o">=</span> <span class="n">bn_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;running_var&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<a id="__codelineno-2-46" name="__codelineno-2-46"></a>
<a id="__codelineno-2-47" name="__codelineno-2-47"></a>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
<a id="__codelineno-2-48" name="__codelineno-2-48"></a>        <span class="c1"># Step 1: 计算均值</span>
<a id="__codelineno-2-49" name="__codelineno-2-49"></a>        <span class="n">sample_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-2-50" name="__codelineno-2-50"></a>
<a id="__codelineno-2-51" name="__codelineno-2-51"></a>        <span class="c1"># Step 2: 计算方差</span>
<a id="__codelineno-2-52" name="__codelineno-2-52"></a>        <span class="n">sample_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-2-53" name="__codelineno-2-53"></a>
<a id="__codelineno-2-54" name="__codelineno-2-54"></a>        <span class="c1"># Step 3: 标准化</span>
<a id="__codelineno-2-55" name="__codelineno-2-55"></a>        <span class="n">x_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">sample_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sample_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
<a id="__codelineno-2-56" name="__codelineno-2-56"></a>
<a id="__codelineno-2-57" name="__codelineno-2-57"></a>        <span class="c1"># Step 4: 缩放 + 平移</span>
<a id="__codelineno-2-58" name="__codelineno-2-58"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">x_hat</span> <span class="o">+</span> <span class="n">beta</span>
<a id="__codelineno-2-59" name="__codelineno-2-59"></a>
<a id="__codelineno-2-60" name="__codelineno-2-60"></a>        <span class="c1"># 缓存中间值供反向传播使用</span>
<a id="__codelineno-2-61" name="__codelineno-2-61"></a>        <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">sample_mean</span><span class="p">,</span> <span class="n">sample_var</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
<a id="__codelineno-2-62" name="__codelineno-2-62"></a>
<a id="__codelineno-2-63" name="__codelineno-2-63"></a>        <span class="c1"># 更新运行中的统计量</span>
<a id="__codelineno-2-64" name="__codelineno-2-64"></a>        <span class="n">running_mean</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">running_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">sample_mean</span>
<a id="__codelineno-2-65" name="__codelineno-2-65"></a>        <span class="n">running_var</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">running_var</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">sample_var</span>
<a id="__codelineno-2-66" name="__codelineno-2-66"></a>    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
<a id="__codelineno-2-67" name="__codelineno-2-67"></a>        <span class="n">x_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">running_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">running_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
<a id="__codelineno-2-68" name="__codelineno-2-68"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">x_hat</span> <span class="o">+</span> <span class="n">beta</span>
<a id="__codelineno-2-69" name="__codelineno-2-69"></a>        <span class="n">cache</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-2-70" name="__codelineno-2-70"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-2-71" name="__codelineno-2-71"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid forward batchnorm mode &quot;</span><span class="si">%s</span><span class="s1">&quot;&#39;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
<a id="__codelineno-2-72" name="__codelineno-2-72"></a>
<a id="__codelineno-2-73" name="__codelineno-2-73"></a>    <span class="c1"># Store the updated running means back into bn_param</span>
<a id="__codelineno-2-74" name="__codelineno-2-74"></a>    <span class="n">bn_param</span><span class="p">[</span><span class="s2">&quot;running_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_mean</span>
<a id="__codelineno-2-75" name="__codelineno-2-75"></a>    <span class="n">bn_param</span><span class="p">[</span><span class="s2">&quot;running_var&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_var</span>
<a id="__codelineno-2-76" name="__codelineno-2-76"></a>
<a id="__codelineno-2-77" name="__codelineno-2-77"></a>    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></td></tr></table></div>
<div class="admonition remarks">
<p class="admonition-title">Remarks</p>
<p>The computation of <span class="arithmatex">\(\mu\)</span> and <span class="arithmatex">\(\sigma\)</span> won't happen in testing. Instead, they will be predicted with train data.</p>
</div>
</div>
<div class="tabbed-block">
<div class="arithmatex">\[
\mu = \frac{1}{m} \sum_{i=1}^{m} x_i
\quad
\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu)^2
\quad
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
\quad
y_i = \gamma \hat{x}_i + \beta
\]</div>
<div class="arithmatex">\[
\frac{\partial L}{\partial \gamma} = \sum_{i=1}^{m} \frac{\partial L}{\partial y_i} \cdot \hat{x}_i
\quad
\frac{\partial L}{\partial \beta} = \sum_{i=1}^{m} \frac{\partial L}{\partial y_i}
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-3-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-3-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-3-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-3-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-3-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-3-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-3-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-3-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-3-10">10</a></span>
<span class="normal"><a href="#__codelineno-3-11">11</a></span>
<span class="normal"><a href="#__codelineno-3-12">12</a></span>
<span class="normal"><a href="#__codelineno-3-13">13</a></span>
<span class="normal"><a href="#__codelineno-3-14">14</a></span>
<span class="normal"><a href="#__codelineno-3-15">15</a></span>
<span class="normal"><a href="#__codelineno-3-16">16</a></span>
<span class="normal"><a href="#__codelineno-3-17">17</a></span>
<span class="normal"><a href="#__codelineno-3-18">18</a></span>
<span class="normal"><a href="#__codelineno-3-19">19</a></span>
<span class="normal"><a href="#__codelineno-3-20">20</a></span>
<span class="normal"><a href="#__codelineno-3-21">21</a></span>
<span class="normal"><a href="#__codelineno-3-22">22</a></span>
<span class="normal"><a href="#__codelineno-3-23">23</a></span>
<span class="normal"><a href="#__codelineno-3-24">24</a></span>
<span class="normal"><a href="#__codelineno-3-25">25</a></span>
<span class="normal"><a href="#__codelineno-3-26">26</a></span>
<span class="normal"><a href="#__codelineno-3-27">27</a></span>
<span class="normal"><a href="#__codelineno-3-28">28</a></span>
<span class="normal"><a href="#__codelineno-3-29">29</a></span>
<span class="normal"><a href="#__codelineno-3-30">30</a></span>
<span class="normal"><a href="#__codelineno-3-31">31</a></span>
<span class="normal"><a href="#__codelineno-3-32">32</a></span>
<span class="normal"><a href="#__codelineno-3-33">33</a></span>
<span class="normal"><a href="#__codelineno-3-34">34</a></span>
<span class="normal"><a href="#__codelineno-3-35">35</a></span>
<span class="normal"><a href="#__codelineno-3-36">36</a></span>
<span class="normal"><a href="#__codelineno-3-37">37</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">batchnorm_backward</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="sd">    Backward pass for batch normalization.</span>
<a id="__codelineno-3-4" name="__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="sd">    For this implementation, you should write out a computation graph for</span>
<a id="__codelineno-3-6" name="__codelineno-3-6"></a><span class="sd">    batch normalization on paper and propagate gradients backward through</span>
<a id="__codelineno-3-7" name="__codelineno-3-7"></a><span class="sd">    intermediate nodes.</span>
<a id="__codelineno-3-8" name="__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-3-10" name="__codelineno-3-10"></a><span class="sd">    - dout: Upstream derivatives, of shape (N, D)</span>
<a id="__codelineno-3-11" name="__codelineno-3-11"></a><span class="sd">    - cache: Variable of intermediates from batchnorm_forward.</span>
<a id="__codelineno-3-12" name="__codelineno-3-12"></a>
<a id="__codelineno-3-13" name="__codelineno-3-13"></a><span class="sd">    Returns a tuple of:</span>
<a id="__codelineno-3-14" name="__codelineno-3-14"></a><span class="sd">    - dx: Gradient with respect to inputs x, of shape (N, D)</span>
<a id="__codelineno-3-15" name="__codelineno-3-15"></a><span class="sd">    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)</span>
<a id="__codelineno-3-16" name="__codelineno-3-16"></a><span class="sd">    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)</span>
<a id="__codelineno-3-17" name="__codelineno-3-17"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-3-18" name="__codelineno-3-18"></a>
<a id="__codelineno-3-19" name="__codelineno-3-19"></a>    <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="n">cache</span>
<a id="__codelineno-3-20" name="__codelineno-3-20"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-3-21" name="__codelineno-3-21"></a>
<a id="__codelineno-3-22" name="__codelineno-3-22"></a>    <span class="c1"># Gradients of beta and gamma</span>
<a id="__codelineno-3-23" name="__codelineno-3-23"></a>    <span class="n">dbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                         <span class="c1"># (D,)</span>
<a id="__codelineno-3-24" name="__codelineno-3-24"></a>    <span class="n">dgamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span> <span class="o">*</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                <span class="c1"># (D,)</span>
<a id="__codelineno-3-25" name="__codelineno-3-25"></a>
<a id="__codelineno-3-26" name="__codelineno-3-26"></a>    <span class="c1"># Gradient of x_hat</span>
<a id="__codelineno-3-27" name="__codelineno-3-27"></a>    <span class="n">dxhat</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="n">gamma</span>                                 <span class="c1"># (N, D)</span>
<a id="__codelineno-3-28" name="__codelineno-3-28"></a>
<a id="__codelineno-3-29" name="__codelineno-3-29"></a>    <span class="c1"># Intermediate partials</span>
<a id="__codelineno-3-30" name="__codelineno-3-30"></a>    <span class="n">dvar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dxhat</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (D,)</span>
<a id="__codelineno-3-31" name="__codelineno-3-31"></a>    <span class="n">dmean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dxhat</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> \
<a id="__codelineno-3-32" name="__codelineno-3-32"></a>            <span class="n">dvar</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                          <span class="c1"># (D,)</span>
<a id="__codelineno-3-33" name="__codelineno-3-33"></a>
<a id="__codelineno-3-34" name="__codelineno-3-34"></a>    <span class="c1"># Final dx</span>
<a id="__codelineno-3-35" name="__codelineno-3-35"></a>    <span class="n">dx</span> <span class="o">=</span> <span class="n">dxhat</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">dvar</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="n">dmean</span> <span class="o">/</span> <span class="n">N</span>  <span class="c1"># (N, D)</span>
<a id="__codelineno-3-36" name="__codelineno-3-36"></a>
<a id="__codelineno-3-37" name="__codelineno-3-37"></a>    <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dgamma</span><span class="p">,</span> <span class="n">dbeta</span>
</code></pre></div></td></tr></table></div>
</div>
<div class="tabbed-block">
<div class="arithmatex">\[
\frac{\partial L}{\partial x_i} = \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}} \cdot \left( 
\frac{\partial L}{\partial y_i} 
- \frac{1}{N} \sum_{j=1}^{N} \frac{\partial L}{\partial y_j}
- \frac{\hat{x}_i}{N} \sum_{j=1}^{N} \left( \frac{\partial L}{\partial y_j} \cdot \hat{x}_j \right)
\right)
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-4-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-4-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-4-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-4-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-4-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-4-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-4-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-4-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-4-10">10</a></span>
<span class="normal"><a href="#__codelineno-4-11">11</a></span>
<span class="normal"><a href="#__codelineno-4-12">12</a></span>
<span class="normal"><a href="#__codelineno-4-13">13</a></span>
<span class="normal"><a href="#__codelineno-4-14">14</a></span>
<span class="normal"><a href="#__codelineno-4-15">15</a></span>
<span class="normal"><a href="#__codelineno-4-16">16</a></span>
<span class="normal"><a href="#__codelineno-4-17">17</a></span>
<span class="normal"><a href="#__codelineno-4-18">18</a></span>
<span class="normal"><a href="#__codelineno-4-19">19</a></span>
<span class="normal"><a href="#__codelineno-4-20">20</a></span>
<span class="normal"><a href="#__codelineno-4-21">21</a></span>
<span class="normal"><a href="#__codelineno-4-22">22</a></span>
<span class="normal"><a href="#__codelineno-4-23">23</a></span>
<span class="normal"><a href="#__codelineno-4-24">24</a></span>
<span class="normal"><a href="#__codelineno-4-25">25</a></span>
<span class="normal"><a href="#__codelineno-4-26">26</a></span>
<span class="normal"><a href="#__codelineno-4-27">27</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">batchnorm_backward_alt</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="sd">    Alternative backward pass for batch normalization.</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a>
<a id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="sd">    For this implementation you should work out the derivatives for the batch</span>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="sd">    normalizaton backward pass on paper and simplify as much as possible. You</span>
<a id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="sd">    should be able to derive a simple expression for the backward pass.</span>
<a id="__codelineno-4-8" name="__codelineno-4-8"></a><span class="sd">    See the jupyter notebook for more hints.</span>
<a id="__codelineno-4-9" name="__codelineno-4-9"></a>
<a id="__codelineno-4-10" name="__codelineno-4-10"></a><span class="sd">    Note: This implementation should expect to receive the same cache variable</span>
<a id="__codelineno-4-11" name="__codelineno-4-11"></a><span class="sd">    as batchnorm_backward, but might not use all of the values in the cache.</span>
<a id="__codelineno-4-12" name="__codelineno-4-12"></a>
<a id="__codelineno-4-13" name="__codelineno-4-13"></a><span class="sd">    Inputs / outputs: Same as batchnorm_backward</span>
<a id="__codelineno-4-14" name="__codelineno-4-14"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-4-15" name="__codelineno-4-15"></a>
<a id="__codelineno-4-16" name="__codelineno-4-16"></a>    <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="n">cache</span>
<a id="__codelineno-4-17" name="__codelineno-4-17"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">dout</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-4-18" name="__codelineno-4-18"></a>
<a id="__codelineno-4-19" name="__codelineno-4-19"></a>    <span class="c1"># Gradients w.r.t. gamma and beta (same as before)</span>
<a id="__codelineno-4-20" name="__codelineno-4-20"></a>    <span class="n">dbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                          <span class="c1"># (D,)</span>
<a id="__codelineno-4-21" name="__codelineno-4-21"></a>    <span class="n">dgamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span> <span class="o">*</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                 <span class="c1"># (D,)</span>
<a id="__codelineno-4-22" name="__codelineno-4-22"></a>
<a id="__codelineno-4-23" name="__codelineno-4-23"></a>    <span class="c1"># Simplified dx expression</span>
<a id="__codelineno-4-24" name="__codelineno-4-24"></a>    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> \
<a id="__codelineno-4-25" name="__codelineno-4-25"></a>        <span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">dout</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">x_hat</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span> <span class="o">*</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-4-26" name="__codelineno-4-26"></a>
<a id="__codelineno-4-27" name="__codelineno-4-27"></a>    <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dgamma</span><span class="p">,</span> <span class="n">dbeta</span>
</code></pre></div></td></tr></table></div>
</div>
</div>
</div>
<h4 id="layer-norm">Layer Norm</h4>
<p>Due to the disadvantages of Batch Norm:
- Sensitive to batch size.
- Not suitable for RNNs and Transformers (Attention based models)
- Behaves differently during training and inference (due to running statistics)</p>
<p>However, LN works on each feature of input data.</p>
<div class="arithmatex">\[
\begin{cases}
\displaystyle \mu = \frac{1}{d} \sum_{i=1}^{d} x_i \\
\displaystyle \sigma = \sqrt{\frac{1}{d} \sum_{i=1}^{d} (x_i - \mu)^2 + \varepsilon} \\
\displaystyle \text{LN}(x_i) = \gamma_i \cdot \frac{x_i - \mu}{\sigma} + \beta_i
\end{cases}
\]</div>
<p>where <span class="arithmatex">\(\gamma_i\)</span> and <span class="arithmatex">\(\beta_i\)</span> can be learnt through training.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Forward</label><label for="__tabbed_3_2">Backward</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-5-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-5-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-5-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-5-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-5-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-5-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-5-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-5-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-5-10">10</a></span>
<span class="normal"><a href="#__codelineno-5-11">11</a></span>
<span class="normal"><a href="#__codelineno-5-12">12</a></span>
<span class="normal"><a href="#__codelineno-5-13">13</a></span>
<span class="normal"><a href="#__codelineno-5-14">14</a></span>
<span class="normal"><a href="#__codelineno-5-15">15</a></span>
<span class="normal"><a href="#__codelineno-5-16">16</a></span>
<span class="normal"><a href="#__codelineno-5-17">17</a></span>
<span class="normal"><a href="#__codelineno-5-18">18</a></span>
<span class="normal"><a href="#__codelineno-5-19">19</a></span>
<span class="normal"><a href="#__codelineno-5-20">20</a></span>
<span class="normal"><a href="#__codelineno-5-21">21</a></span>
<span class="normal"><a href="#__codelineno-5-22">22</a></span>
<span class="normal"><a href="#__codelineno-5-23">23</a></span>
<span class="normal"><a href="#__codelineno-5-24">24</a></span>
<span class="normal"><a href="#__codelineno-5-25">25</a></span>
<span class="normal"><a href="#__codelineno-5-26">26</a></span>
<span class="normal"><a href="#__codelineno-5-27">27</a></span>
<span class="normal"><a href="#__codelineno-5-28">28</a></span>
<span class="normal"><a href="#__codelineno-5-29">29</a></span>
<span class="normal"><a href="#__codelineno-5-30">30</a></span>
<span class="normal"><a href="#__codelineno-5-31">31</a></span>
<span class="normal"><a href="#__codelineno-5-32">32</a></span>
<span class="normal"><a href="#__codelineno-5-33">33</a></span>
<span class="normal"><a href="#__codelineno-5-34">34</a></span>
<span class="normal"><a href="#__codelineno-5-35">35</a></span>
<span class="normal"><a href="#__codelineno-5-36">36</a></span>
<span class="normal"><a href="#__codelineno-5-37">37</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">layernorm_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">ln_param</span><span class="p">):</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="sd">    Forward pass for layer normalization.</span>
<a id="__codelineno-5-4" name="__codelineno-5-4"></a>
<a id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="sd">    During both training and test-time, the incoming data is normalized per data-point,</span>
<a id="__codelineno-5-6" name="__codelineno-5-6"></a><span class="sd">    before being scaled by gamma and beta parameters identical to that of batch normalization.</span>
<a id="__codelineno-5-7" name="__codelineno-5-7"></a>
<a id="__codelineno-5-8" name="__codelineno-5-8"></a><span class="sd">    Note that in contrast to batch normalization, the behavior during train and test-time for</span>
<a id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="sd">    layer normalization are identical, and we do not need to keep track of running averages</span>
<a id="__codelineno-5-10" name="__codelineno-5-10"></a><span class="sd">    of any sort.</span>
<a id="__codelineno-5-11" name="__codelineno-5-11"></a>
<a id="__codelineno-5-12" name="__codelineno-5-12"></a><span class="sd">    Input:</span>
<a id="__codelineno-5-13" name="__codelineno-5-13"></a><span class="sd">    - x: Data of shape (N, D)</span>
<a id="__codelineno-5-14" name="__codelineno-5-14"></a><span class="sd">    - gamma: Scale parameter of shape (D,)</span>
<a id="__codelineno-5-15" name="__codelineno-5-15"></a><span class="sd">    - beta: Shift paremeter of shape (D,)</span>
<a id="__codelineno-5-16" name="__codelineno-5-16"></a><span class="sd">    - ln_param: Dictionary with the following keys:</span>
<a id="__codelineno-5-17" name="__codelineno-5-17"></a><span class="sd">        - eps: Constant for numeric stability</span>
<a id="__codelineno-5-18" name="__codelineno-5-18"></a>
<a id="__codelineno-5-19" name="__codelineno-5-19"></a><span class="sd">    Returns a tuple of:</span>
<a id="__codelineno-5-20" name="__codelineno-5-20"></a><span class="sd">    - out: of shape (N, D)</span>
<a id="__codelineno-5-21" name="__codelineno-5-21"></a><span class="sd">    - cache: A tuple of values needed in the backward pass</span>
<a id="__codelineno-5-22" name="__codelineno-5-22"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-5-23" name="__codelineno-5-23"></a>
<a id="__codelineno-5-24" name="__codelineno-5-24"></a>    <span class="n">eps</span> <span class="o">=</span> <span class="n">ln_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
<a id="__codelineno-5-25" name="__codelineno-5-25"></a>
<a id="__codelineno-5-26" name="__codelineno-5-26"></a>    <span class="c1"># Step 1: Compute mean and variance per data point (along axis=1)</span>
<a id="__codelineno-5-27" name="__codelineno-5-27"></a>    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># shape (N, 1)</span>
<a id="__codelineno-5-28" name="__codelineno-5-28"></a>    <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>    <span class="c1"># shape (N, 1)</span>
<a id="__codelineno-5-29" name="__codelineno-5-29"></a>
<a id="__codelineno-5-30" name="__codelineno-5-30"></a>    <span class="c1"># Step 2: Normalize</span>
<a id="__codelineno-5-31" name="__codelineno-5-31"></a>    <span class="n">x_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>   <span class="c1"># shape (N, D)</span>
<a id="__codelineno-5-32" name="__codelineno-5-32"></a>
<a id="__codelineno-5-33" name="__codelineno-5-33"></a>    <span class="c1"># Step 3: Scale and shift</span>
<a id="__codelineno-5-34" name="__codelineno-5-34"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">x_hat</span> <span class="o">+</span> <span class="n">beta</span>                <span class="c1"># shape (N, D)</span>
<a id="__codelineno-5-35" name="__codelineno-5-35"></a>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
<a id="__codelineno-5-36" name="__codelineno-5-36"></a>
<a id="__codelineno-5-37" name="__codelineno-5-37"></a>    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></td></tr></table></div>
</div>
<div class="tabbed-block">
<div class="arithmatex">\[
\frac{\partial L}{\partial x_i} =
\frac{1}{D} \cdot \frac{1}{\sqrt{\sigma_i^2 + \epsilon}} \cdot \left(
D \cdot \frac{\partial L}{\partial \hat{x}_i} -
\sum_{j=1}^{D} \frac{\partial L}{\partial \hat{x}_{ij}} -
\hat{x}_i \cdot \sum_{j=1}^{D} \left( \frac{\partial L}{\partial \hat{x}_{ij}} \cdot \hat{x}_{ij} \right)
\right)
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-6-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-6-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-6-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-6-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-6-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-6-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-6-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-6-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-6-10">10</a></span>
<span class="normal"><a href="#__codelineno-6-11">11</a></span>
<span class="normal"><a href="#__codelineno-6-12">12</a></span>
<span class="normal"><a href="#__codelineno-6-13">13</a></span>
<span class="normal"><a href="#__codelineno-6-14">14</a></span>
<span class="normal"><a href="#__codelineno-6-15">15</a></span>
<span class="normal"><a href="#__codelineno-6-16">16</a></span>
<span class="normal"><a href="#__codelineno-6-17">17</a></span>
<span class="normal"><a href="#__codelineno-6-18">18</a></span>
<span class="normal"><a href="#__codelineno-6-19">19</a></span>
<span class="normal"><a href="#__codelineno-6-20">20</a></span>
<span class="normal"><a href="#__codelineno-6-21">21</a></span>
<span class="normal"><a href="#__codelineno-6-22">22</a></span>
<span class="normal"><a href="#__codelineno-6-23">23</a></span>
<span class="normal"><a href="#__codelineno-6-24">24</a></span>
<span class="normal"><a href="#__codelineno-6-25">25</a></span>
<span class="normal"><a href="#__codelineno-6-26">26</a></span>
<span class="normal"><a href="#__codelineno-6-27">27</a></span>
<span class="normal"><a href="#__codelineno-6-28">28</a></span>
<span class="normal"><a href="#__codelineno-6-29">29</a></span>
<span class="normal"><a href="#__codelineno-6-30">30</a></span>
<span class="normal"><a href="#__codelineno-6-31">31</a></span>
<span class="normal"><a href="#__codelineno-6-32">32</a></span>
<span class="normal"><a href="#__codelineno-6-33">33</a></span>
<span class="normal"><a href="#__codelineno-6-34">34</a></span>
<span class="normal"><a href="#__codelineno-6-35">35</a></span>
<span class="normal"><a href="#__codelineno-6-36">36</a></span>
<span class="normal"><a href="#__codelineno-6-37">37</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">layernorm_backward</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
<a id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-6-3" name="__codelineno-6-3"></a><span class="sd">    Backward pass for layer normalization.</span>
<a id="__codelineno-6-4" name="__codelineno-6-4"></a>
<a id="__codelineno-6-5" name="__codelineno-6-5"></a><span class="sd">    For this implementation, you can heavily rely on the work you&#39;ve done already</span>
<a id="__codelineno-6-6" name="__codelineno-6-6"></a><span class="sd">    for batch normalization.</span>
<a id="__codelineno-6-7" name="__codelineno-6-7"></a>
<a id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="sd">    - dout: Upstream derivatives, of shape (N, D)</span>
<a id="__codelineno-6-10" name="__codelineno-6-10"></a><span class="sd">    - cache: Variable of intermediates from layernorm_forward.</span>
<a id="__codelineno-6-11" name="__codelineno-6-11"></a>
<a id="__codelineno-6-12" name="__codelineno-6-12"></a><span class="sd">    Returns a tuple of:</span>
<a id="__codelineno-6-13" name="__codelineno-6-13"></a><span class="sd">    - dx: Gradient with respect to inputs x, of shape (N, D)</span>
<a id="__codelineno-6-14" name="__codelineno-6-14"></a><span class="sd">    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)</span>
<a id="__codelineno-6-15" name="__codelineno-6-15"></a><span class="sd">    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)</span>
<a id="__codelineno-6-16" name="__codelineno-6-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-6-17" name="__codelineno-6-17"></a>
<a id="__codelineno-6-18" name="__codelineno-6-18"></a>    <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="n">cache</span>
<a id="__codelineno-6-19" name="__codelineno-6-19"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-6-20" name="__codelineno-6-20"></a>
<a id="__codelineno-6-21" name="__codelineno-6-21"></a>    <span class="c1"># dbeta 和 dgamma 很简单：按列求和</span>
<a id="__codelineno-6-22" name="__codelineno-6-22"></a>    <span class="n">dbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>            <span class="c1"># shape (D,)</span>
<a id="__codelineno-6-23" name="__codelineno-6-23"></a>    <span class="n">dgamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dout</span> <span class="o">*</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># shape (D,)</span>
<a id="__codelineno-6-24" name="__codelineno-6-24"></a>
<a id="__codelineno-6-25" name="__codelineno-6-25"></a>    <span class="c1"># dx_hat</span>
<a id="__codelineno-6-26" name="__codelineno-6-26"></a>    <span class="n">dxhat</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="n">gamma</span>                    <span class="c1"># shape (N, D)</span>
<a id="__codelineno-6-27" name="__codelineno-6-27"></a>
<a id="__codelineno-6-28" name="__codelineno-6-28"></a>    <span class="c1"># 参考 BatchNorm 的链式法则公式，适配按行归一化</span>
<a id="__codelineno-6-29" name="__codelineno-6-29"></a>    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>                <span class="c1"># shape (N, 1)</span>
<a id="__codelineno-6-30" name="__codelineno-6-30"></a>
<a id="__codelineno-6-31" name="__codelineno-6-31"></a>    <span class="c1"># 向量形式的 dx</span>
<a id="__codelineno-6-32" name="__codelineno-6-32"></a>    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">D</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">std</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
<a id="__codelineno-6-33" name="__codelineno-6-33"></a>        <span class="n">D</span> <span class="o">*</span> <span class="n">dxhat</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dxhat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-6-34" name="__codelineno-6-34"></a>        <span class="o">-</span> <span class="n">x_hat</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dxhat</span> <span class="o">*</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-6-35" name="__codelineno-6-35"></a>    <span class="p">)</span>
<a id="__codelineno-6-36" name="__codelineno-6-36"></a>
<a id="__codelineno-6-37" name="__codelineno-6-37"></a>    <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dgamma</span><span class="p">,</span> <span class="n">dbeta</span>
</code></pre></div></td></tr></table></div>
</div>
</div>
</div>
<p><em>Other normalizations</em></p>
<p><img alt="img.png" src="../img.png" /></p>
<blockquote>
<p><strong>C</strong>: Channels (Features), <strong>N</strong> Batch Size, <strong>H, W</strong>: data dimentions.</p>
</blockquote>
<h3 id="regularization">Regularization</h3>
<h4 id="stochastic-depth">Stochastic Depth</h4>
<p>(?)</p>
<h4 id="dropout">Dropout</h4>
<p>In each forward pass, randomly set some neurons to zero. Probability of dropping is a hyperparameter; 0.5 is common. </p>
<p>At test time, all neurons are active always.</p>
<div class="admonition normal-comment">
<p class="admonition-title">A rule to be obeyed</p>
<p>The output at test time must be the same as the expected output at training time</p>
</div>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Forward</label><label for="__tabbed_4_2">Backward</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="arithmatex">\[
\text{mask}_i \sim \text{Bernoulli}(p)
\quad\Rightarrow\quad
\text{mask}_i = \frac{\mathbf{1}_{[u_i &lt; p]}}{p}
\]</div>
<div class="arithmatex">\[
\text{out}_i = x_i \cdot \text{mask}_i
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-7-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-7-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-7-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-7-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-7-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-7-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-7-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-7-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-7-10">10</a></span>
<span class="normal"><a href="#__codelineno-7-11">11</a></span>
<span class="normal"><a href="#__codelineno-7-12">12</a></span>
<span class="normal"><a href="#__codelineno-7-13">13</a></span>
<span class="normal"><a href="#__codelineno-7-14">14</a></span>
<span class="normal"><a href="#__codelineno-7-15">15</a></span>
<span class="normal"><a href="#__codelineno-7-16">16</a></span>
<span class="normal"><a href="#__codelineno-7-17">17</a></span>
<span class="normal"><a href="#__codelineno-7-18">18</a></span>
<span class="normal"><a href="#__codelineno-7-19">19</a></span>
<span class="normal"><a href="#__codelineno-7-20">20</a></span>
<span class="normal"><a href="#__codelineno-7-21">21</a></span>
<span class="normal"><a href="#__codelineno-7-22">22</a></span>
<span class="normal"><a href="#__codelineno-7-23">23</a></span>
<span class="normal"><a href="#__codelineno-7-24">24</a></span>
<span class="normal"><a href="#__codelineno-7-25">25</a></span>
<span class="normal"><a href="#__codelineno-7-26">26</a></span>
<span class="normal"><a href="#__codelineno-7-27">27</a></span>
<span class="normal"><a href="#__codelineno-7-28">28</a></span>
<span class="normal"><a href="#__codelineno-7-29">29</a></span>
<span class="normal"><a href="#__codelineno-7-30">30</a></span>
<span class="normal"><a href="#__codelineno-7-31">31</a></span>
<span class="normal"><a href="#__codelineno-7-32">32</a></span>
<span class="normal"><a href="#__codelineno-7-33">33</a></span>
<span class="normal"><a href="#__codelineno-7-34">34</a></span>
<span class="normal"><a href="#__codelineno-7-35">35</a></span>
<span class="normal"><a href="#__codelineno-7-36">36</a></span>
<span class="normal"><a href="#__codelineno-7-37">37</a></span>
<span class="normal"><a href="#__codelineno-7-38">38</a></span>
<span class="normal"><a href="#__codelineno-7-39">39</a></span>
<span class="normal"><a href="#__codelineno-7-40">40</a></span>
<span class="normal"><a href="#__codelineno-7-41">41</a></span>
<span class="normal"><a href="#__codelineno-7-42">42</a></span>
<span class="normal"><a href="#__codelineno-7-43">43</a></span>
<span class="normal"><a href="#__codelineno-7-44">44</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">dropout_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dropout_param</span><span class="p">):</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="sd">    Performs the forward pass for (inverted) dropout.</span>
<a id="__codelineno-7-4" name="__codelineno-7-4"></a>
<a id="__codelineno-7-5" name="__codelineno-7-5"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="sd">    - x: Input data, of any shape</span>
<a id="__codelineno-7-7" name="__codelineno-7-7"></a><span class="sd">    - dropout_param: A dictionary with the following keys:</span>
<a id="__codelineno-7-8" name="__codelineno-7-8"></a><span class="sd">      - p: Dropout parameter. We keep each neuron output with probability p.</span>
<a id="__codelineno-7-9" name="__codelineno-7-9"></a><span class="sd">      - mode: &#39;test&#39; or &#39;train&#39;. If the mode is train, then perform dropout;</span>
<a id="__codelineno-7-10" name="__codelineno-7-10"></a><span class="sd">        if the mode is test, then just return the input.</span>
<a id="__codelineno-7-11" name="__codelineno-7-11"></a><span class="sd">      - seed: Seed for the random number generator. Passing seed makes this</span>
<a id="__codelineno-7-12" name="__codelineno-7-12"></a><span class="sd">        function deterministic, which is needed for gradient checking but not</span>
<a id="__codelineno-7-13" name="__codelineno-7-13"></a><span class="sd">        in real networks.</span>
<a id="__codelineno-7-14" name="__codelineno-7-14"></a>
<a id="__codelineno-7-15" name="__codelineno-7-15"></a><span class="sd">    Outputs:</span>
<a id="__codelineno-7-16" name="__codelineno-7-16"></a><span class="sd">    - out: Array of the same shape as x.</span>
<a id="__codelineno-7-17" name="__codelineno-7-17"></a><span class="sd">    - cache: tuple (dropout_param, mask). In training mode, mask is the dropout</span>
<a id="__codelineno-7-18" name="__codelineno-7-18"></a><span class="sd">      mask that was used to multiply the input; in test mode, mask is None.</span>
<a id="__codelineno-7-19" name="__codelineno-7-19"></a>
<a id="__codelineno-7-20" name="__codelineno-7-20"></a><span class="sd">    NOTE: Please implement **inverted** dropout, not the vanilla version of dropout.</span>
<a id="__codelineno-7-21" name="__codelineno-7-21"></a><span class="sd">    See http://cs231n.github.io/neural-networks-2/#reg for more details.</span>
<a id="__codelineno-7-22" name="__codelineno-7-22"></a>
<a id="__codelineno-7-23" name="__codelineno-7-23"></a><span class="sd">    NOTE 2: Keep in mind that p is the probability of **keep** a neuron</span>
<a id="__codelineno-7-24" name="__codelineno-7-24"></a><span class="sd">    output; this might be contrary to some sources, where it is referred to</span>
<a id="__codelineno-7-25" name="__codelineno-7-25"></a><span class="sd">    as the probability of dropping a neuron output.</span>
<a id="__codelineno-7-26" name="__codelineno-7-26"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-7-27" name="__codelineno-7-27"></a>    <span class="n">p</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="n">dropout_param</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">],</span> <span class="n">dropout_param</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span>
<a id="__codelineno-7-28" name="__codelineno-7-28"></a>    <span class="k">if</span> <span class="s2">&quot;seed&quot;</span> <span class="ow">in</span> <span class="n">dropout_param</span><span class="p">:</span>
<a id="__codelineno-7-29" name="__codelineno-7-29"></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">dropout_param</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">])</span>
<a id="__codelineno-7-30" name="__codelineno-7-30"></a>
<a id="__codelineno-7-31" name="__codelineno-7-31"></a>    <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-7-32" name="__codelineno-7-32"></a>    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-7-33" name="__codelineno-7-33"></a>
<a id="__codelineno-7-34" name="__codelineno-7-34"></a>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
<a id="__codelineno-7-35" name="__codelineno-7-35"></a>        <span class="c1"># 生成 dropout mask，1的概率为p，0的概率为1-p</span>
<a id="__codelineno-7-36" name="__codelineno-7-36"></a>        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span>  <span class="c1"># 注意是除以 p</span>
<a id="__codelineno-7-37" name="__codelineno-7-37"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>                             <span class="c1"># 应用 mask</span>
<a id="__codelineno-7-38" name="__codelineno-7-38"></a>    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
<a id="__codelineno-7-39" name="__codelineno-7-39"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-7-40" name="__codelineno-7-40"></a>
<a id="__codelineno-7-41" name="__codelineno-7-41"></a>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">dropout_param</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<a id="__codelineno-7-42" name="__codelineno-7-42"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-7-43" name="__codelineno-7-43"></a>
<a id="__codelineno-7-44" name="__codelineno-7-44"></a>    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></td></tr></table></div>
</div>
<div class="tabbed-block">
<div class="arithmatex">\[
\frac{\partial L}{\partial x_i} = \frac{\partial L}{\partial \text{out}_i} \cdot \text{mask}_i
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-8-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-8-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-8-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-8-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-8-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-8-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-8-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-8-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-8-10">10</a></span>
<span class="normal"><a href="#__codelineno-8-11">11</a></span>
<span class="normal"><a href="#__codelineno-8-12">12</a></span>
<span class="normal"><a href="#__codelineno-8-13">13</a></span>
<span class="normal"><a href="#__codelineno-8-14">14</a></span>
<span class="normal"><a href="#__codelineno-8-15">15</a></span>
<span class="normal"><a href="#__codelineno-8-16">16</a></span>
<span class="normal"><a href="#__codelineno-8-17">17</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">dropout_backward</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
<a id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-8-3" name="__codelineno-8-3"></a><span class="sd">    Perform the backward pass for (inverted) dropout.</span>
<a id="__codelineno-8-4" name="__codelineno-8-4"></a>
<a id="__codelineno-8-5" name="__codelineno-8-5"></a><span class="sd">    Inputs:</span>
<a id="__codelineno-8-6" name="__codelineno-8-6"></a><span class="sd">    - dout: Upstream derivatives, of any shape</span>
<a id="__codelineno-8-7" name="__codelineno-8-7"></a><span class="sd">    - cache: (dropout_param, mask) from dropout_forward.</span>
<a id="__codelineno-8-8" name="__codelineno-8-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-8-9" name="__codelineno-8-9"></a>    <span class="n">dropout_param</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">cache</span>
<a id="__codelineno-8-10" name="__codelineno-8-10"></a>    <span class="n">mode</span> <span class="o">=</span> <span class="n">dropout_param</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span>
<a id="__codelineno-8-11" name="__codelineno-8-11"></a>
<a id="__codelineno-8-12" name="__codelineno-8-12"></a>    <span class="n">dx</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-8-13" name="__codelineno-8-13"></a>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
<a id="__codelineno-8-14" name="__codelineno-8-14"></a>        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="n">mask</span>
<a id="__codelineno-8-15" name="__codelineno-8-15"></a>    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
<a id="__codelineno-8-16" name="__codelineno-8-16"></a>        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span>
<a id="__codelineno-8-17" name="__codelineno-8-17"></a>    <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></td></tr></table></div>
</div>
</div>
</div>
<h4 id="fractional-max-pooling">Fractional Max Pooling</h4>
<p>(?)</p>
<h2 id="activation-functions">Activation Functions</h2>
<h3 id="sigmoid">Sigmoid</h3>
<div class="arithmatex">\[
\sigma(x) = 1 / (1 + \mathrm{e}^{-x})
\]</div>
<blockquote>
<p>Key problem: Large positive or negative values can “kill” the gradients.</p>
</blockquote>
<h3 id="relu">ReLU</h3>
<div class="arithmatex">\[
f(x) = \max \{0, x\}
\]</div>
<blockquote>
<p>Main benefit: High efficiency, does not saturate in <span class="arithmatex">\(+\)</span> region<br />
Key Problem: Not zero-centered, deaded values when <span class="arithmatex">\(x &lt; 0\)</span>.</p>
</blockquote>
<h3 id="gelu">GELU</h3>
<div class="arithmatex">\[
\mathrm{GELU}(x) = x \cdot \Phi(x)
\]</div>
<p>where </p>
<div class="arithmatex">\[
\Phi (x) = \frac{1}{2} \left[1 + \mathrm{erf}\left(\frac{x}{\sqrt{2}}\right)\right]
\]</div>
<h3 id="other-lus">Other LUs</h3>
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>                <div id="b706c30e-cad3-4edc-9603-0824410b2f7f" class="plotly-graph-div" style="height:400px; width:900px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("b706c30e-cad3-4edc-9603-0824410b2f7f")) {                    Plotly.newPlot(                        "b706c30e-cad3-4edc-9603-0824410b2f7f",                        [{"name":"ELU","x":[-5.0,-4.979959919839679,-4.959919839679359,-4.939879759519038,-4.919839679358717,-4.8997995991983965,-4.8797595190380765,-4.859719438877756,-4.839679358717435,-4.819639278557114,-4.799599198396794,-4.779559118236473,-4.759519038076152,-4.739478957915832,-4.719438877755511,-4.69939879759519,-4.679358717434869,-4.659318637274549,-4.6392785571142285,-4.619238476953908,-4.599198396793588,-4.579158316633267,-4.559118236472946,-4.539078156312625,-4.519038076152305,-4.498997995991984,-4.478957915831663,-4.458917835671342,-4.438877755511022,-4.4188376753507015,-4.398797595190381,-4.37875751503006,-4.35871743486974,-4.338677354709419,-4.318637274549098,-4.298597194388778,-4.278557114228457,-4.258517034068136,-4.238476953907815,-4.218436873747495,-4.198396793587174,-4.1783567134268536,-4.158316633266534,-4.138276553106213,-4.118236472945892,-4.098196392785571,-4.078156312625251,-4.05811623246493,-4.038076152304609,-4.018036072144288,-3.9979959919839683,-3.9779559118236474,-3.9579158316633265,-3.937875751503006,-3.9178356713426856,-3.8977955911823647,-3.877755511022044,-3.8577154308617234,-3.837675350701403,-3.817635270541082,-3.7975951903807617,-3.777555110220441,-3.7575150300601203,-3.7374749498997994,-3.717434869739479,-3.6973947895791586,-3.6773547094188377,-3.657314629258517,-3.6372745490981964,-3.617234468937876,-3.597194388777555,-3.5771543086172346,-3.557114228456914,-3.5370741482965933,-3.5170340681362724,-3.496993987975952,-3.4769539078156315,-3.4569138276553106,-3.4368737474949898,-3.4168336673346693,-3.396793587174349,-3.376753507014028,-3.3567134268537075,-3.336673346693387,-3.3166332665330662,-3.2965931863727453,-3.276553106212425,-3.2565130260521045,-3.2364729458917836,-3.2164328657314627,-3.1963927855711423,-3.176352705410822,-3.156312625250501,-3.1362725450901805,-3.11623246492986,-3.096192384769539,-3.0761523046092183,-3.056112224448898,-3.0360721442885774,-3.0160320641282565,-2.995991983967936,-2.975951903807615,-2.9559118236472948,-2.935871743486974,-2.9158316633266534,-2.8957915831663326,-2.875751503006012,-2.8557114228456917,-2.835671342685371,-2.8156312625250504,-2.7955911823647295,-2.775551102204409,-2.755511022044088,-2.7354709418837677,-2.715430861723447,-2.6953907815631264,-2.6753507014028055,-2.655310621242485,-2.6352705410821646,-2.6152304609218437,-2.5951903807615233,-2.5751503006012024,-2.555110220440882,-2.535070140280561,-2.5150300601202407,-2.49498997995992,-2.4749498997995993,-2.4549098196392785,-2.434869739478958,-2.4148296593186376,-2.3947895791583167,-2.3747494989979963,-2.3547094188376754,-2.334669338677355,-2.314629258517034,-2.2945891783567136,-2.2745490981963927,-2.2545090180360723,-2.2344689378757514,-2.214428857715431,-2.1943887775551105,-2.1743486973947896,-2.154308617234469,-2.1342685370741483,-2.114228456913828,-2.094188376753507,-2.0741482965931866,-2.0541082164328657,-2.0340681362725452,-2.0140280561122244,-1.993987975951904,-1.9739478957915835,-1.9539078156312626,-1.9338677354709422,-1.9138276553106213,-1.8937875751503008,-1.87374749498998,-1.8537074148296595,-1.8336673346693386,-1.8136272545090182,-1.7935871743486977,-1.7735470941883769,-1.7535070140280564,-1.7334669338677355,-1.713426853707415,-1.6933867735470942,-1.6733466933867738,-1.653306613226453,-1.6332665330661325,-1.6132264529058116,-1.5931863727454911,-1.5731462925851707,-1.5531062124248498,-1.5330661322645294,-1.5130260521042085,-1.492985971943888,-1.4729458917835672,-1.4529058116232467,-1.4328657314629258,-1.4128256513026054,-1.3927855711422845,-1.372745490981964,-1.3527054108216436,-1.3326653306613228,-1.3126252505010023,-1.2925851703406814,-1.272545090180361,-1.25250501002004,-1.2324649298597197,-1.2124248496993988,-1.1923847695390783,-1.1723446893787575,-1.152304609218437,-1.1322645290581166,-1.1122244488977957,-1.0921843687374753,-1.0721442885771544,-1.052104208416834,-1.032064128256513,-1.0120240480961926,-0.9919839679358722,-0.9719438877755513,-0.9519038076152304,-0.9318637274549104,-0.9118236472945895,-0.8917835671342687,-0.8717434869739478,-0.8517034068136278,-0.8316633266533069,-0.811623246492986,-0.7915831663326651,-0.7715430861723451,-0.7515030060120242,-0.7314629258517034,-0.7114228456913834,-0.6913827655310625,-0.6713426853707416,-0.6513026052104207,-0.6312625250501007,-0.6112224448897798,-0.591182364729459,-0.5711422845691381,-0.5511022044088181,-0.5310621242484972,-0.5110220440881763,-0.4909819639278563,-0.47094188376753543,-0.45090180360721455,-0.43086172344689366,-0.41082164328657367,-0.3907815631262528,-0.3707414829659319,-0.350701402805611,-0.330661322645291,-0.31062124248497014,-0.29058116232464926,-0.27054108216432926,-0.2505010020040084,-0.2304609218436875,-0.2104208416833666,-0.19038076152304662,-0.17034068136272573,-0.15030060120240485,-0.13026052104208397,-0.11022044088176397,-0.09018036072144309,-0.0701402805611222,-0.05010020040080221,-0.030060120240481325,-0.010020040080160442,0.010020040080160442,0.030060120240480437,0.05010020040080132,0.0701402805611222,0.09018036072144309,0.11022044088176308,0.13026052104208397,0.15030060120240485,0.17034068136272484,0.19038076152304573,0.2104208416833666,0.2304609218436875,0.2505010020040075,0.2705410821643284,0.29058116232464926,0.31062124248497014,0.33066132264529013,0.350701402805611,0.3707414829659319,0.3907815631262519,0.4108216432865728,0.43086172344689366,0.45090180360721455,0.47094188376753454,0.4909819639278554,0.5110220440881763,0.5310621242484972,0.5511022044088172,0.5711422845691381,0.591182364729459,0.611222444889779,0.6312625250500998,0.6513026052104207,0.6713426853707416,0.6913827655310616,0.7114228456913825,0.7314629258517034,0.7515030060120242,0.7715430861723442,0.7915831663326651,0.811623246492986,0.831663326653306,0.8517034068136269,0.8717434869739478,0.8917835671342687,0.9118236472945886,0.9318637274549095,0.9519038076152304,0.9719438877755513,0.9919839679358713,1.0120240480961922,1.032064128256513,1.052104208416833,1.072144288577154,1.0921843687374748,1.1122244488977957,1.1322645290581157,1.1523046092184366,1.1723446893787575,1.1923847695390783,1.2124248496993983,1.2324649298597192,1.25250501002004,1.27254509018036,1.292585170340681,1.3126252505010019,1.3326653306613228,1.3527054108216428,1.3727454909819636,1.3927855711422845,1.4128256513026045,1.4328657314629254,1.4529058116232463,1.4729458917835672,1.4929859719438872,1.513026052104208,1.533066132264529,1.5531062124248498,1.5731462925851698,1.5931863727454907,1.6132264529058116,1.6332665330661316,1.6533066132264524,1.6733466933867733,1.6933867735470942,1.7134268537074142,1.733466933867735,1.753507014028056,1.7735470941883769,1.7935871743486969,1.8136272545090177,1.8336673346693386,1.8537074148296586,1.8737474949899795,1.8937875751503004,1.9138276553106213,1.9338677354709413,1.9539078156312621,1.973947895791583,1.993987975951904,2.014028056112224,2.034068136272545,2.0541082164328657,2.0741482965931857,2.0941883767535066,2.1142284569138274,2.1342685370741483,2.1543086172344683,2.174348697394789,2.19438877755511,2.214428857715431,2.234468937875751,2.254509018036072,2.2745490981963927,2.2945891783567127,2.3146292585170336,2.3346693386773545,2.3547094188376754,2.3747494989979954,2.3947895791583163,2.414829659318637,2.434869739478958,2.454909819639278,2.474949899799599,2.49498997995992,2.5150300601202398,2.5350701402805607,2.5551102204408815,2.5751503006012024,2.5951903807615224,2.6152304609218433,2.635270541082164,2.655310621242485,2.675350701402805,2.695390781563126,2.715430861723447,2.735470941883767,2.7555110220440877,2.7755511022044086,2.7955911823647295,2.8156312625250495,2.8356713426853704,2.8557114228456912,2.875751503006012,2.895791583166332,2.915831663326653,2.935871743486974,2.955911823647294,2.9759519038076148,2.9959919839679356,3.0160320641282556,3.0360721442885765,3.0561122244488974,3.0761523046092183,3.096192384769539,3.11623246492986,3.136272545090179,3.1563126252505,3.176352705410821,3.196392785571142,3.2164328657314627,3.2364729458917836,3.2565130260521045,3.2765531062124253,3.2965931863727445,3.3166332665330653,3.336673346693386,3.356713426853707,3.376753507014028,3.396793587174349,3.4168336673346698,3.436873747494989,3.4569138276553097,3.4769539078156306,3.4969939879759515,3.5170340681362724,3.5370741482965933,3.557114228456914,3.5771543086172333,3.597194388777554,3.617234468937875,3.637274549098196,3.657314629258517,3.6773547094188377,3.6973947895791586,3.7174348697394795,3.7374749498997986,3.7575150300601194,3.7775551102204403,3.797595190380761,3.817635270541082,3.837675350701403,3.857715430861724,3.877755511022043,3.897795591182364,3.9178356713426847,3.9378757515030056,3.9579158316633265,3.9779559118236474,3.9979959919839683,4.018036072144287,4.038076152304608,4.058116232464929,4.07815631262525,4.098196392785571,4.118236472945892,4.138276553106213,4.158316633266534,4.178356713426853,4.1983967935871735,4.218436873747494,4.238476953907815,4.258517034068136,4.278557114228457,4.298597194388778,4.318637274549097,4.338677354709418,4.358717434869739,4.37875751503006,4.398797595190381,4.4188376753507015,4.438877755511022,4.4589178356713415,4.478957915831662,4.498997995991983,4.519038076152304,4.539078156312625,4.559118236472946,4.579158316633267,4.599198396793588,4.619238476953907,4.639278557114228,4.6593186372745485,4.679358717434869,4.69939879759519,4.719438877755511,4.739478957915832,4.759519038076151,4.779559118236472,4.799599198396793,4.819639278557114,4.839679358717435,4.859719438877756,4.8797595190380765,4.899799599198396,4.9198396793587165,4.939879759519037,4.959919839679358,4.979959919839679,5.0],"y":[-0.9932620530009145,-0.993125661923453,-0.9929865099863389,-0.9928445413036142,-0.9926996988580645,-0.9925519244783199,-0.992401158815492,-0.9922473413193384,-0.9920904102139453,-0.991930302472916,-0.9917669537940592,-0.9916002985735638,-0.9914302698796512,-0.9912567994256943,-0.9910798175427924,-0.9908992531517906,-0.9907150337347337,-0.9905270853057411,-0.9903353323812929,-0.9901396979499146,-0.9899401034412476,-0.9897364686944937,-0.9895287119262217,-0.9893167496975211,-0.9891004968804918,-0.9888798666240551,-0.9886547703190728,-0.9884251175627599,-0.9881908161223775,-0.9879517718981904,-0.9877078888856747,-0.9874590691369608,-0.987205212721496,-0.9869462176859097,-0.9866819800130683,-0.9864123935802991,-0.9861373501167696,-0.9858567391600045,-0.9855704480115214,-0.9852783616915692,-0.9849803628929503,-0.9846763319339075,-0.984366146710058,-0.984049682645354,-0.9837268126420505,-0.9833974070296606,-0.9830613335128777,-0.9827184571184427,-0.982368640140937,-0.9820117420874772,-0.9816476196212901,-0.9812761265041469,-0.9808971135376306,-0.9805104285032157,-0.9801159161011337,-0.9797134178880029,-0.9793027722131938,-0.9788838141539078,-0.9784563754489406,-0.9780202844311062,-0.9775753659582915,-0.9771214413431166,-0.9766583282811702,-0.9761858407777931,-0.9757037890733796,-0.9752119795671659,-0.974710214739477,-0.9741982930723992,-0.9736760089688468,-0.9731431526699899,-0.9725995101710124,-0.9720448631351636,-0.9714789888060694,-0.9709016599182702,-0.9703126446059461,-0.9697117063097963,-0.9690986036820316,-0.9684730904894456,-0.9678349155145222,-0.9671838224545425,-0.966519549818649,-0.9658418308228255,-0.9651503932827528,-0.9644449595044935,-0.9637252461729655,-0.9629909642381577,-0.9622418187990418,-0.9614775089851347,-0.960697727835664,-0.9599021621762862,-0.9590904924933106,-0.9582623928053767,-0.9574175305325341,-0.9565555663626721,-0.9556761541152464,-0.954778940602246,-0.9538635654863465,-0.9529296611361929,-0.951976852478751,-0.9510047568486717,-0.9500129838346058,-0.9490011351224075,-0.9479688043351641,-0.9469155768699878,-0.9458410297315035,-0.9447447313619661,-0.9436262414679389,-0.9424851108434642,-0.9413208811896535,-0.9401330849306264,-0.9389212450257239,-0.9376848747779198,-0.9364234776383544,-0.9351365470069115,-0.9338235660287585,-0.9324840073867678,-0.9311173330897374,-0.9297229942563229,-0.9283004308945969,-0.9268490716771467,-0.9253683337116182,-0.9238576223066155,-0.9223163307328627,-0.9207438399795297,-0.9191395185056264,-0.9175027219863642,-0.9158327930543838,-0.914129061035744,-0.9123908416805668,-0.9106174368882307,-0.9088081344269999,-0.9069622076479801,-0.9050789151932819,-0.9031575006982788,-0.9011971924878369,-0.8991972032663964,-0.8971567298017791,-0.8950749526025957,-0.8929510355891231,-0.8907841257575198,-0.8885733528372436,-0.8863178289415351,-0.8840166482108267,-0.8816688864489322,-0.8792736007518729,-0.8768298291291905,-0.8743365901175939,-0.8717928823867854,-0.8691976843373088,-0.8665499536902558,-0.863848627068668,-0.8610926195704655,-0.8582808243327299,-0.8554121120871687,-0.8524853307065798,-0.8494993047421368,-0.8464528349513064,-0.8433446978162122,-0.8401736450522459,-0.8369384031067346,-0.8336376726474585,-0.8302701280408148,-0.82683441681942,-0.8233291591389338,-0.8197529472238883,-0.8161043448022995,-0.8123818865288355,-0.8085840773963051,-0.8047093921352376,-0.8007562746013052,-0.7967231371503478,-0.7926083600007463,-0.7884102905828878,-0.7841272428754646,-0.7797574967283365,-0.7752992971716877,-0.7707508537111979,-0.7661103396089485,-0.7613758911497699,-0.7565456068927406,-0.7516175469075331,-0.7465897319953028,-0.7414601428938055,-0.7362267194664247,-0.7308873598747836,-0.7254399197346078,-0.7198822112545019,-0.7142120023572924,-0.708427015783585,-0.7025249281771748,-0.6965033691519453,-0.6903599203398771,-0.6840921144197876,-0.6776974341264093,-0.6711733112394109,-0.664517125551953,-0.6577262038183639,-0.6507978186805174,-0.6437291875724742,-0.6365174716029542,-0.6291597744151843,-0.6216531410236696,-0.6139945566274179,-0.6061809453991394,-0.5982091692499378,-0.590076026568999,-0.5817782509377638,-0.5733125098180749,-0.5646754032137682,-0.5558634623051739,-0.5468731480559741,-0.5377008497918614,-0.5283428837504254,-0.5187954916016877,-0.5090548389386885,-0.4991170137375158,-0.4889780247861687,-0.47863380008161194,-0.46808018519438555,-0.45731294160010927,-0.4463277449772156,-0.43512018347022197,-0.42368575591784996,-0.4120198700452746,-0.4001178406197863,-0.3879748875691138,-0.3755861340616592,-0.36294660454787553,-0.35005122276199396,-0.3368948096833032,-0.3234720814561587,-0.3097776472678925,-0.2958060071837626,-0.28155154993807974,-0.2670085506806186,-0.2521711686774165,-0.23703344496502687,-0.22158929995728827,-0.20583253100365595,-0.18975680989810095,-0.1733556803375893,-0.15662255532910907,-0.13955071454421886,-0.12213330162003766,-0.10436332140560645,-0.0862336371525042,-0.06773696764860482,-0.04886588429380634,-0.029612808116567746,-0.0099700067300601,0.010020040080160442,0.030060120240480437,0.05010020040080132,0.0701402805611222,0.09018036072144309,0.11022044088176308,0.13026052104208397,0.15030060120240485,0.17034068136272484,0.19038076152304573,0.2104208416833666,0.2304609218436875,0.2505010020040075,0.2705410821643284,0.29058116232464926,0.31062124248497014,0.33066132264529013,0.350701402805611,0.3707414829659319,0.3907815631262519,0.4108216432865728,0.43086172344689366,0.45090180360721455,0.47094188376753454,0.4909819639278554,0.5110220440881763,0.5310621242484972,0.5511022044088172,0.5711422845691381,0.591182364729459,0.611222444889779,0.6312625250500998,0.6513026052104207,0.6713426853707416,0.6913827655310616,0.7114228456913825,0.7314629258517034,0.7515030060120242,0.7715430861723442,0.7915831663326651,0.811623246492986,0.831663326653306,0.8517034068136269,0.8717434869739478,0.8917835671342687,0.9118236472945886,0.9318637274549095,0.9519038076152304,0.9719438877755513,0.9919839679358713,1.0120240480961922,1.032064128256513,1.052104208416833,1.072144288577154,1.0921843687374748,1.1122244488977957,1.1322645290581157,1.1523046092184366,1.1723446893787575,1.1923847695390783,1.2124248496993983,1.2324649298597192,1.25250501002004,1.27254509018036,1.292585170340681,1.3126252505010019,1.3326653306613228,1.3527054108216428,1.3727454909819636,1.3927855711422845,1.4128256513026045,1.4328657314629254,1.4529058116232463,1.4729458917835672,1.4929859719438872,1.513026052104208,1.533066132264529,1.5531062124248498,1.5731462925851698,1.5931863727454907,1.6132264529058116,1.6332665330661316,1.6533066132264524,1.6733466933867733,1.6933867735470942,1.7134268537074142,1.733466933867735,1.753507014028056,1.7735470941883769,1.7935871743486969,1.8136272545090177,1.8336673346693386,1.8537074148296586,1.8737474949899795,1.8937875751503004,1.9138276553106213,1.9338677354709413,1.9539078156312621,1.973947895791583,1.993987975951904,2.014028056112224,2.034068136272545,2.0541082164328657,2.0741482965931857,2.0941883767535066,2.1142284569138274,2.1342685370741483,2.1543086172344683,2.174348697394789,2.19438877755511,2.214428857715431,2.234468937875751,2.254509018036072,2.2745490981963927,2.2945891783567127,2.3146292585170336,2.3346693386773545,2.3547094188376754,2.3747494989979954,2.3947895791583163,2.414829659318637,2.434869739478958,2.454909819639278,2.474949899799599,2.49498997995992,2.5150300601202398,2.5350701402805607,2.5551102204408815,2.5751503006012024,2.5951903807615224,2.6152304609218433,2.635270541082164,2.655310621242485,2.675350701402805,2.695390781563126,2.715430861723447,2.735470941883767,2.7555110220440877,2.7755511022044086,2.7955911823647295,2.8156312625250495,2.8356713426853704,2.8557114228456912,2.875751503006012,2.895791583166332,2.915831663326653,2.935871743486974,2.955911823647294,2.9759519038076148,2.9959919839679356,3.0160320641282556,3.0360721442885765,3.0561122244488974,3.0761523046092183,3.096192384769539,3.11623246492986,3.136272545090179,3.1563126252505,3.176352705410821,3.196392785571142,3.2164328657314627,3.2364729458917836,3.2565130260521045,3.2765531062124253,3.2965931863727445,3.3166332665330653,3.336673346693386,3.356713426853707,3.376753507014028,3.396793587174349,3.4168336673346698,3.436873747494989,3.4569138276553097,3.4769539078156306,3.4969939879759515,3.5170340681362724,3.5370741482965933,3.557114228456914,3.5771543086172333,3.597194388777554,3.617234468937875,3.637274549098196,3.657314629258517,3.6773547094188377,3.6973947895791586,3.7174348697394795,3.7374749498997986,3.7575150300601194,3.7775551102204403,3.797595190380761,3.817635270541082,3.837675350701403,3.857715430861724,3.877755511022043,3.897795591182364,3.9178356713426847,3.9378757515030056,3.9579158316633265,3.9779559118236474,3.9979959919839683,4.018036072144287,4.038076152304608,4.058116232464929,4.07815631262525,4.098196392785571,4.118236472945892,4.138276553106213,4.158316633266534,4.178356713426853,4.1983967935871735,4.218436873747494,4.238476953907815,4.258517034068136,4.278557114228457,4.298597194388778,4.318637274549097,4.338677354709418,4.358717434869739,4.37875751503006,4.398797595190381,4.4188376753507015,4.438877755511022,4.4589178356713415,4.478957915831662,4.498997995991983,4.519038076152304,4.539078156312625,4.559118236472946,4.579158316633267,4.599198396793588,4.619238476953907,4.639278557114228,4.6593186372745485,4.679358717434869,4.69939879759519,4.719438877755511,4.739478957915832,4.759519038076151,4.779559118236472,4.799599198396793,4.819639278557114,4.839679358717435,4.859719438877756,4.8797595190380765,4.899799599198396,4.9198396793587165,4.939879759519037,4.959919839679358,4.979959919839679,5.0],"type":"scatter","xaxis":"x","yaxis":"y"},{"name":"GELU","x":[-5.0,-4.979959919839679,-4.959919839679359,-4.939879759519038,-4.919839679358717,-4.8997995991983965,-4.8797595190380765,-4.859719438877756,-4.839679358717435,-4.819639278557114,-4.799599198396794,-4.779559118236473,-4.759519038076152,-4.739478957915832,-4.719438877755511,-4.69939879759519,-4.679358717434869,-4.659318637274549,-4.6392785571142285,-4.619238476953908,-4.599198396793588,-4.579158316633267,-4.559118236472946,-4.539078156312625,-4.519038076152305,-4.498997995991984,-4.478957915831663,-4.458917835671342,-4.438877755511022,-4.4188376753507015,-4.398797595190381,-4.37875751503006,-4.35871743486974,-4.338677354709419,-4.318637274549098,-4.298597194388778,-4.278557114228457,-4.258517034068136,-4.238476953907815,-4.218436873747495,-4.198396793587174,-4.1783567134268536,-4.158316633266534,-4.138276553106213,-4.118236472945892,-4.098196392785571,-4.078156312625251,-4.05811623246493,-4.038076152304609,-4.018036072144288,-3.9979959919839683,-3.9779559118236474,-3.9579158316633265,-3.937875751503006,-3.9178356713426856,-3.8977955911823647,-3.877755511022044,-3.8577154308617234,-3.837675350701403,-3.817635270541082,-3.7975951903807617,-3.777555110220441,-3.7575150300601203,-3.7374749498997994,-3.717434869739479,-3.6973947895791586,-3.6773547094188377,-3.657314629258517,-3.6372745490981964,-3.617234468937876,-3.597194388777555,-3.5771543086172346,-3.557114228456914,-3.5370741482965933,-3.5170340681362724,-3.496993987975952,-3.4769539078156315,-3.4569138276553106,-3.4368737474949898,-3.4168336673346693,-3.396793587174349,-3.376753507014028,-3.3567134268537075,-3.336673346693387,-3.3166332665330662,-3.2965931863727453,-3.276553106212425,-3.2565130260521045,-3.2364729458917836,-3.2164328657314627,-3.1963927855711423,-3.176352705410822,-3.156312625250501,-3.1362725450901805,-3.11623246492986,-3.096192384769539,-3.0761523046092183,-3.056112224448898,-3.0360721442885774,-3.0160320641282565,-2.995991983967936,-2.975951903807615,-2.9559118236472948,-2.935871743486974,-2.9158316633266534,-2.8957915831663326,-2.875751503006012,-2.8557114228456917,-2.835671342685371,-2.8156312625250504,-2.7955911823647295,-2.775551102204409,-2.755511022044088,-2.7354709418837677,-2.715430861723447,-2.6953907815631264,-2.6753507014028055,-2.655310621242485,-2.6352705410821646,-2.6152304609218437,-2.5951903807615233,-2.5751503006012024,-2.555110220440882,-2.535070140280561,-2.5150300601202407,-2.49498997995992,-2.4749498997995993,-2.4549098196392785,-2.434869739478958,-2.4148296593186376,-2.3947895791583167,-2.3747494989979963,-2.3547094188376754,-2.334669338677355,-2.314629258517034,-2.2945891783567136,-2.2745490981963927,-2.2545090180360723,-2.2344689378757514,-2.214428857715431,-2.1943887775551105,-2.1743486973947896,-2.154308617234469,-2.1342685370741483,-2.114228456913828,-2.094188376753507,-2.0741482965931866,-2.0541082164328657,-2.0340681362725452,-2.0140280561122244,-1.993987975951904,-1.9739478957915835,-1.9539078156312626,-1.9338677354709422,-1.9138276553106213,-1.8937875751503008,-1.87374749498998,-1.8537074148296595,-1.8336673346693386,-1.8136272545090182,-1.7935871743486977,-1.7735470941883769,-1.7535070140280564,-1.7334669338677355,-1.713426853707415,-1.6933867735470942,-1.6733466933867738,-1.653306613226453,-1.6332665330661325,-1.6132264529058116,-1.5931863727454911,-1.5731462925851707,-1.5531062124248498,-1.5330661322645294,-1.5130260521042085,-1.492985971943888,-1.4729458917835672,-1.4529058116232467,-1.4328657314629258,-1.4128256513026054,-1.3927855711422845,-1.372745490981964,-1.3527054108216436,-1.3326653306613228,-1.3126252505010023,-1.2925851703406814,-1.272545090180361,-1.25250501002004,-1.2324649298597197,-1.2124248496993988,-1.1923847695390783,-1.1723446893787575,-1.152304609218437,-1.1322645290581166,-1.1122244488977957,-1.0921843687374753,-1.0721442885771544,-1.052104208416834,-1.032064128256513,-1.0120240480961926,-0.9919839679358722,-0.9719438877755513,-0.9519038076152304,-0.9318637274549104,-0.9118236472945895,-0.8917835671342687,-0.8717434869739478,-0.8517034068136278,-0.8316633266533069,-0.811623246492986,-0.7915831663326651,-0.7715430861723451,-0.7515030060120242,-0.7314629258517034,-0.7114228456913834,-0.6913827655310625,-0.6713426853707416,-0.6513026052104207,-0.6312625250501007,-0.6112224448897798,-0.591182364729459,-0.5711422845691381,-0.5511022044088181,-0.5310621242484972,-0.5110220440881763,-0.4909819639278563,-0.47094188376753543,-0.45090180360721455,-0.43086172344689366,-0.41082164328657367,-0.3907815631262528,-0.3707414829659319,-0.350701402805611,-0.330661322645291,-0.31062124248497014,-0.29058116232464926,-0.27054108216432926,-0.2505010020040084,-0.2304609218436875,-0.2104208416833666,-0.19038076152304662,-0.17034068136272573,-0.15030060120240485,-0.13026052104208397,-0.11022044088176397,-0.09018036072144309,-0.0701402805611222,-0.05010020040080221,-0.030060120240481325,-0.010020040080160442,0.010020040080160442,0.030060120240480437,0.05010020040080132,0.0701402805611222,0.09018036072144309,0.11022044088176308,0.13026052104208397,0.15030060120240485,0.17034068136272484,0.19038076152304573,0.2104208416833666,0.2304609218436875,0.2505010020040075,0.2705410821643284,0.29058116232464926,0.31062124248497014,0.33066132264529013,0.350701402805611,0.3707414829659319,0.3907815631262519,0.4108216432865728,0.43086172344689366,0.45090180360721455,0.47094188376753454,0.4909819639278554,0.5110220440881763,0.5310621242484972,0.5511022044088172,0.5711422845691381,0.591182364729459,0.611222444889779,0.6312625250500998,0.6513026052104207,0.6713426853707416,0.6913827655310616,0.7114228456913825,0.7314629258517034,0.7515030060120242,0.7715430861723442,0.7915831663326651,0.811623246492986,0.831663326653306,0.8517034068136269,0.8717434869739478,0.8917835671342687,0.9118236472945886,0.9318637274549095,0.9519038076152304,0.9719438877755513,0.9919839679358713,1.0120240480961922,1.032064128256513,1.052104208416833,1.072144288577154,1.0921843687374748,1.1122244488977957,1.1322645290581157,1.1523046092184366,1.1723446893787575,1.1923847695390783,1.2124248496993983,1.2324649298597192,1.25250501002004,1.27254509018036,1.292585170340681,1.3126252505010019,1.3326653306613228,1.3527054108216428,1.3727454909819636,1.3927855711422845,1.4128256513026045,1.4328657314629254,1.4529058116232463,1.4729458917835672,1.4929859719438872,1.513026052104208,1.533066132264529,1.5531062124248498,1.5731462925851698,1.5931863727454907,1.6132264529058116,1.6332665330661316,1.6533066132264524,1.6733466933867733,1.6933867735470942,1.7134268537074142,1.733466933867735,1.753507014028056,1.7735470941883769,1.7935871743486969,1.8136272545090177,1.8336673346693386,1.8537074148296586,1.8737474949899795,1.8937875751503004,1.9138276553106213,1.9338677354709413,1.9539078156312621,1.973947895791583,1.993987975951904,2.014028056112224,2.034068136272545,2.0541082164328657,2.0741482965931857,2.0941883767535066,2.1142284569138274,2.1342685370741483,2.1543086172344683,2.174348697394789,2.19438877755511,2.214428857715431,2.234468937875751,2.254509018036072,2.2745490981963927,2.2945891783567127,2.3146292585170336,2.3346693386773545,2.3547094188376754,2.3747494989979954,2.3947895791583163,2.414829659318637,2.434869739478958,2.454909819639278,2.474949899799599,2.49498997995992,2.5150300601202398,2.5350701402805607,2.5551102204408815,2.5751503006012024,2.5951903807615224,2.6152304609218433,2.635270541082164,2.655310621242485,2.675350701402805,2.695390781563126,2.715430861723447,2.735470941883767,2.7555110220440877,2.7755511022044086,2.7955911823647295,2.8156312625250495,2.8356713426853704,2.8557114228456912,2.875751503006012,2.895791583166332,2.915831663326653,2.935871743486974,2.955911823647294,2.9759519038076148,2.9959919839679356,3.0160320641282556,3.0360721442885765,3.0561122244488974,3.0761523046092183,3.096192384769539,3.11623246492986,3.136272545090179,3.1563126252505,3.176352705410821,3.196392785571142,3.2164328657314627,3.2364729458917836,3.2565130260521045,3.2765531062124253,3.2965931863727445,3.3166332665330653,3.336673346693386,3.356713426853707,3.376753507014028,3.396793587174349,3.4168336673346698,3.436873747494989,3.4569138276553097,3.4769539078156306,3.4969939879759515,3.5170340681362724,3.5370741482965933,3.557114228456914,3.5771543086172333,3.597194388777554,3.617234468937875,3.637274549098196,3.657314629258517,3.6773547094188377,3.6973947895791586,3.7174348697394795,3.7374749498997986,3.7575150300601194,3.7775551102204403,3.797595190380761,3.817635270541082,3.837675350701403,3.857715430861724,3.877755511022043,3.897795591182364,3.9178356713426847,3.9378757515030056,3.9579158316633265,3.9779559118236474,3.9979959919839683,4.018036072144287,4.038076152304608,4.058116232464929,4.07815631262525,4.098196392785571,4.118236472945892,4.138276553106213,4.158316633266534,4.178356713426853,4.1983967935871735,4.218436873747494,4.238476953907815,4.258517034068136,4.278557114228457,4.298597194388778,4.318637274549097,4.338677354709418,4.358717434869739,4.37875751503006,4.398797595190381,4.4188376753507015,4.438877755511022,4.4589178356713415,4.478957915831662,4.498997995991983,4.519038076152304,4.539078156312625,4.559118236472946,4.579158316633267,4.599198396793588,4.619238476953907,4.639278557114228,4.6593186372745485,4.679358717434869,4.69939879759519,4.719438877755511,4.739478957915832,4.759519038076151,4.779559118236472,4.799599198396793,4.819639278557114,4.839679358717435,4.859719438877756,4.8797595190380765,4.899799599198396,4.9198396793587165,4.939879759519037,4.959919839679358,4.979959919839679,5.0],"y":[-2.2917961972623857e-07,-2.622469906285001e-07,-2.998238211812548e-07,-3.424871641877281e-07,-3.908826959003085e-07,-4.457322009934433e-07,-5.078417849300739e-07,-5.781108843225641e-07,-6.575421383600226e-07,-7.47252191184887e-07,-8.484835034071713e-07,-9.62617251380857e-07,-1.0911873994837534e-06,-1.235896038963255e-06,-1.3986300837477408e-06,-1.5814794310092528e-06,-1.7867566894979144e-06,-2.0170185883574225e-06,-2.275089189516751e-06,-2.564085023420881e-06,-2.887442281761719e-06,-3.248946205315175e-06,-3.652762807952244e-06,-4.103473086470589e-06,-4.606109876058671e-06,-5.1661975071228835e-06,-5.789794436537351e-06,-6.483539025782494e-06,-7.254698645319578e-06,-8.111222289962681e-06,-9.061796898629948e-06,-1.0115907571593948e-05,-1.1283901887236668e-05,-1.2577058522729782e-05,-1.4007660386213563e-05,-1.558907247616635e-05,-1.7335824676761056e-05,-1.9263699712683964e-05,-2.1389826476229273e-05,-2.3732778949810333e-05,-2.6312680938645095e-05,-2.9151316835977433e-05,-3.2272248632988694e-05,-3.570093938682152e-05,-3.9464883354699196e-05,-4.359374300003911e-05,-4.8119493062360144e-05,-5.307657188222165e-05,-5.850204015983428e-05,-6.443574731416308e-05,-7.092050560089753e-05,-7.800227212847983e-05,-8.573033890019744e-05,-9.415753099077904e-05,-0.00010334041294772553,-0.00011333950348785839,-0.00012421949853316398,-0.00013604950261098548,-0.00014890326861346308,-0.00016285944588142768,-0.0001780018365543801,-0.00019441966008839747,-0.00021220782581346905,-0.00023146721336566347,-0.0002523049607910776,-0.00027483476007621644,-0.00029917715982333363,-0.0003254598747391309,-0.00035381810156164147,-0.00038439484100860155,-0.00041734122527029954,-0.00045281685053139855,-0.0004909901139449859,-0.0005320385544339971,-0.0005761491966388594,-0.0006235188972712938,-0.0006743546930843532,-0.0007288741496006824,-0.0007873057096922727,-0.0008498890410372975,-0.000916875381425696,-0.0009885278808177383,-0.0010651219390098265,-0.0011469455376880223,-0.001234299565600782,-0.0013274981355160553,-0.0014268688915694827,-0.0015327533055533682,-0.0016455069606372882,-0.0017654998209527706,-0.0018931164854244771,-0.002028756424170328,-0.0021728341957458256,-0.0023257796434583105,-0.0024880380689249514,-0.0026600703810104095,-0.002842353218230243,-0.0030353790426745765,-0.0032396562034658527,-0.0034557089677321566,-0.003684077517051091,-0.00392531790729462,-0.0041800019897785595,-0.00444871729161362,-0.004732066853133963,-0.005030669020277748,-0.005345157189790601,-0.005676179505122969,-0.00602439850090904,-0.006390490693918601,-0.006775146118402925,-0.0071790678037747125,-0.007602971192602673,-0.008047583496930251,-0.008513642990985539,-0.00900189823839181,-0.009513107252056733,-0.010048036584979344,-0.010607460350291488,-0.01119215916893576,-0.011802919043465547,-0.0124405301565597,-0.013105785592944293,-0.01379947998353373,-0.0145224080707261,-0.015275363193918801,-0.01605913569445366,-0.016874511239351703,-0.01772226906335441,-0.018603180128959482,-0.019518005204316218,-0.02046749285903186,-0.021452377378138304,-0.02247337659467102,-0.023531189641532155,-0.024626494623527433,-0.02575994621070551,-0.026932173154365732,-0.02814377572735596,-0.029395323090536527,-0.030687350587559257,-0.032020356970382836,-0.033394801558231345,-0.03481110133299382,-0.03626962797435899,-0.03777070483828684,-0.03931460388272411,-0.040901542544790906,-0.04253168057398086,-0.04420511682624475,-0.04592188602414918,-0.047681955488633715,-0.04948522184821628,-0.051331507731827236,-0.05322055845177887,-0.05515203868370116,-0.057125529150599534,-0.0591405233185026,-0.06119642411147892,-0.06329254065410402,-0.06542808504975227,-0.06760216920336343,-0.06981380169761076,-0.07206188473164243,-0.0743452111318115,-0.07666246144402662,-0.07901220111755282,-0.08139287779027614,-0.08380281868559186,-0.08624022813121164,-0.08870318521028224,-0.09118964155528535,-0.09369741929522546,-0.09622420916662616,-0.09876756879882974,-0.10132492118403359,-0.10389355334240201,-0.10647061519245443,-0.10905311863675728,-0.11163793687272862,-0.11422180393810938,-0.1168013145003505,-0.11937292389882602,-0.1219329484483883,-0.12447756601235711,-0.12700281685255096,-0.12950460476345477,-0.1319786984970528,-0.13442073348424774,-0.13682621385814317,-0.13919051478377206,-0.14150888509813073,-0.14377645026360691,-0.14598821563709183,-0.14813907005622634,-0.15022378974336703,-0.15223704252695897,-0.15417339237907896,-0.1560273042669705,-0.15779314931542138,-0.15946521027585867,-0.16103768729703657,-0.1625047039911926,-0.16386031378853924,-0.16509850657194944,-0.16621321558268723,-0.16719832458704165,-0.16804767529273218,-0.16875507500298745,-0.16931430449525017,-0.16971912611053713,-0.16996329203859065,-0.17004055278309568,-0.1699446657904163,-0.16966940422452229,-0.16920856587004193,-0.1685559821446923,-0.16770552720170223,-0.1666511271022677,-0.16538676903756125,-0.16390651057935898,-0.1622044889379585,-0.16027493020573447,-0.15811215856442223,-0.15571060543403611,-0.15306481854120887,-0.15016947088470342,-0.1470193695758762,-0.14360946453197745,-0.13993485700035507,-0.13599080789188056,-0.1317727459022452,-0.12727627540017078,-0.12249718406205322,-0.11743145023309513,-0.11207524999559741,-0.10642496392574845,-0.10047718352099368,-0.09422871728087037,-0.08767659642504534,-0.08081808023321678,-0.07365066099250284,-0.06617206853896564,-0.05838027438097146,-0.050273495393205025,-0.041850197071291194,-0.03310909633816547,-0.024049163894531593,-0.01466962610698935,-0.004969966428674206,0.005050073651486236,0.015390494133491509,0.026051036506270137,0.03703118422295673,0.04833016365015189,0.05994694548855843,0.0718802466611125,0.08412853266343921,0.09669002037022234,0.10956268128982927,0.12274424525832127,0.13623220456281712,0.15002381848301408,0.16411611823858016,0.17850591232905183,0.19318979225187502,0.20816413858323712,0.22342512740544024,0.2389687370636867,0.2547907552343715,0.2708867862862179,0.28725225891491624,0.30388243403133836,0.32077241288283126,0.33791714538664663,0.3553114386541402,0.37294996568407496,0.39082727420308283,0.40893779563117955,0.42727585415009994,0.4458356758522178,0.4646113979478322,0.48359707800871854,0.5027867032260492,0.5221741996610196,0.5417534414668602,0.561518260061287,0.5814624532289285,0.6015797941337536,0.6218640402221279,0.6423089419977358,0.6629082516503185,0.6836557315208946,0.7045451623869061,0.7255703515515814,0.7467251407226391,0.7680034136663703,0.7893991036240378,0.8109062004785148,0.8325187576600125,0.8542308987807709,0.8760368239895425,0.897930816037754,0.9199072460501948,0.9419605789941078,0.9640853788415693,0.9862763134210237,1.0085281589548296,1.0308358042806267,1.0531942547553064,1.075598635841255,1.0980441963754715,1.1205263115229873,1.1430404854169052,1.16558235348813,1.1881476844886447,1.2107323822129346,1.2333324869228168,1.255944176481613,1.2785637672041752,1.3011877144298758,1.3238126128261682,1.3464351964307917,1.369052338441165,1.3916610507598535,1.4142584833053784,1.4368419230979026,1.4594087931296242,1.4819566510298843,1.5044831875352085,1.5269862247745998,1.5494637143805396,1.5719137354361763,1.5943344922692206,1.6167243121030677,1.6390816425756025,1.6614050491360928,1.683693212330445,1.7059449249850134,1.7281590892989445,1.7503347138549137,1.7724709105578595,1.794566891511156,1.8166219658393798,1.8386355364665992,1.8606070968588424,1.882536227739114,1.904422593783046,1.9262659403029492,1.9480660899277547,1.9698229392859792,1.991536455698564,2.013206673888075,2.0348336927104613,2.0564176719152196,2.0779588289394684,2.0994574357411544,2.120913815676237,2.1423283404244065,2.1637014269675507,2.1850335346248944,2.206325162148395,2.227576844881706,2.248789151985687,2.269962683733185,2.2910980688755016,2.3121959620826833,2.3332570414595373,2.3542820061389635,2.375271573954,2.3962264791896777,2.4171474704156037,2.438035308399926,2.458890764105145,2.479714616766001,2.5005076520495138,2.5212706602970267,2.542004434847937,2.5627097704446427,2.5833874617180568,2.604038301752907,2.6246630807318727,2.6452625846575057,2.6658375941507484,2.686388883324734,2.7069172187324613,2.7274233583868366,2.747908050851485,2.768372034400634,2.7888160362463266,2.809240771831131,2.829646944184461,2.8500352433405682,2.8704063458162214,2.890760914146054,2.911099596473519,2.93142302619536,2.9517318216575155,2.9720265859003203,2.9923079064508844,3.012576355160524,3.0328324880851105,3.0530768454062227,3.073309951390988,3.0935323143885287,3.113744426860935,3.133946765446721,3.1541397910547544,3.174323948986651,3.1944996690857175,3.21466736591051,3.234827438931146,3.2549802727465513,3.275126237320856,3.295265688237228,3.3153989669674644,3.335526401155698,3.3556483049146975,3.3757649791332103,3.395876711792923,3.4159837782936324,3.4360864417852968,3.456184953505709,3.4762795531225463,3.4963704690786805,3.516457918939633,3.536542109742159,3.556623238342969,3.5767014917667015,3.596777047552284,3.6168500740968663,3.6369207309966343,3.6569891693837775,3.677055532259014,3.6971199548190827,3.7171825647786885,3.737243482686433,3.757302822234306,3.777360690560352,3.7974171885442067,3.817472411095201,3.83752644743279,3.857579381359113,3.87763129152351,3.8976822516788756,3.917732330929737,3.937781593972015,3.957830101324426,3.977877909551519,3.997925071478367,4.017971636396973,4.0380176502644485,4.058063155893047,4.078108193132188,4.098152799042571,4.118197008062537,4.138240852166826,4.158284361017901,4.178327562110017,4.1983704809062345,4.218413140968545,4.238455564081339,4.2584977703684235,4.27853977840378,4.2985816053163015,4.318623266888711,4.338664777650895,4.358706150967851,4.378747399122489,4.398788533393482,4.418829564128411,4.438870500812377,4.458911352132316,4.4789521260372265,4.498992829794476,4.5190334700424275,4.539074052839538,4.559114583710138,4.579155067687061,4.599195509351306,4.619235912868883,4.639276282025038,4.65931662025596,4.679356930678179,4.699397216115759,4.719437479125427,4.739477722019793,4.759517946888752,4.77955815561922,4.79959834991329,4.819638531304923,4.839678701175297,4.859718860766871,4.879759011196292,4.899799153466195,4.9198392884760205,4.939879417031873,4.959919539855537,4.979959657592689,4.999999770820381],"type":"scatter","xaxis":"x2","yaxis":"y2"},{"name":"SiLU","x":[-5.0,-4.979959919839679,-4.959919839679359,-4.939879759519038,-4.919839679358717,-4.8997995991983965,-4.8797595190380765,-4.859719438877756,-4.839679358717435,-4.819639278557114,-4.799599198396794,-4.779559118236473,-4.759519038076152,-4.739478957915832,-4.719438877755511,-4.69939879759519,-4.679358717434869,-4.659318637274549,-4.6392785571142285,-4.619238476953908,-4.599198396793588,-4.579158316633267,-4.559118236472946,-4.539078156312625,-4.519038076152305,-4.498997995991984,-4.478957915831663,-4.458917835671342,-4.438877755511022,-4.4188376753507015,-4.398797595190381,-4.37875751503006,-4.35871743486974,-4.338677354709419,-4.318637274549098,-4.298597194388778,-4.278557114228457,-4.258517034068136,-4.238476953907815,-4.218436873747495,-4.198396793587174,-4.1783567134268536,-4.158316633266534,-4.138276553106213,-4.118236472945892,-4.098196392785571,-4.078156312625251,-4.05811623246493,-4.038076152304609,-4.018036072144288,-3.9979959919839683,-3.9779559118236474,-3.9579158316633265,-3.937875751503006,-3.9178356713426856,-3.8977955911823647,-3.877755511022044,-3.8577154308617234,-3.837675350701403,-3.817635270541082,-3.7975951903807617,-3.777555110220441,-3.7575150300601203,-3.7374749498997994,-3.717434869739479,-3.6973947895791586,-3.6773547094188377,-3.657314629258517,-3.6372745490981964,-3.617234468937876,-3.597194388777555,-3.5771543086172346,-3.557114228456914,-3.5370741482965933,-3.5170340681362724,-3.496993987975952,-3.4769539078156315,-3.4569138276553106,-3.4368737474949898,-3.4168336673346693,-3.396793587174349,-3.376753507014028,-3.3567134268537075,-3.336673346693387,-3.3166332665330662,-3.2965931863727453,-3.276553106212425,-3.2565130260521045,-3.2364729458917836,-3.2164328657314627,-3.1963927855711423,-3.176352705410822,-3.156312625250501,-3.1362725450901805,-3.11623246492986,-3.096192384769539,-3.0761523046092183,-3.056112224448898,-3.0360721442885774,-3.0160320641282565,-2.995991983967936,-2.975951903807615,-2.9559118236472948,-2.935871743486974,-2.9158316633266534,-2.8957915831663326,-2.875751503006012,-2.8557114228456917,-2.835671342685371,-2.8156312625250504,-2.7955911823647295,-2.775551102204409,-2.755511022044088,-2.7354709418837677,-2.715430861723447,-2.6953907815631264,-2.6753507014028055,-2.655310621242485,-2.6352705410821646,-2.6152304609218437,-2.5951903807615233,-2.5751503006012024,-2.555110220440882,-2.535070140280561,-2.5150300601202407,-2.49498997995992,-2.4749498997995993,-2.4549098196392785,-2.434869739478958,-2.4148296593186376,-2.3947895791583167,-2.3747494989979963,-2.3547094188376754,-2.334669338677355,-2.314629258517034,-2.2945891783567136,-2.2745490981963927,-2.2545090180360723,-2.2344689378757514,-2.214428857715431,-2.1943887775551105,-2.1743486973947896,-2.154308617234469,-2.1342685370741483,-2.114228456913828,-2.094188376753507,-2.0741482965931866,-2.0541082164328657,-2.0340681362725452,-2.0140280561122244,-1.993987975951904,-1.9739478957915835,-1.9539078156312626,-1.9338677354709422,-1.9138276553106213,-1.8937875751503008,-1.87374749498998,-1.8537074148296595,-1.8336673346693386,-1.8136272545090182,-1.7935871743486977,-1.7735470941883769,-1.7535070140280564,-1.7334669338677355,-1.713426853707415,-1.6933867735470942,-1.6733466933867738,-1.653306613226453,-1.6332665330661325,-1.6132264529058116,-1.5931863727454911,-1.5731462925851707,-1.5531062124248498,-1.5330661322645294,-1.5130260521042085,-1.492985971943888,-1.4729458917835672,-1.4529058116232467,-1.4328657314629258,-1.4128256513026054,-1.3927855711422845,-1.372745490981964,-1.3527054108216436,-1.3326653306613228,-1.3126252505010023,-1.2925851703406814,-1.272545090180361,-1.25250501002004,-1.2324649298597197,-1.2124248496993988,-1.1923847695390783,-1.1723446893787575,-1.152304609218437,-1.1322645290581166,-1.1122244488977957,-1.0921843687374753,-1.0721442885771544,-1.052104208416834,-1.032064128256513,-1.0120240480961926,-0.9919839679358722,-0.9719438877755513,-0.9519038076152304,-0.9318637274549104,-0.9118236472945895,-0.8917835671342687,-0.8717434869739478,-0.8517034068136278,-0.8316633266533069,-0.811623246492986,-0.7915831663326651,-0.7715430861723451,-0.7515030060120242,-0.7314629258517034,-0.7114228456913834,-0.6913827655310625,-0.6713426853707416,-0.6513026052104207,-0.6312625250501007,-0.6112224448897798,-0.591182364729459,-0.5711422845691381,-0.5511022044088181,-0.5310621242484972,-0.5110220440881763,-0.4909819639278563,-0.47094188376753543,-0.45090180360721455,-0.43086172344689366,-0.41082164328657367,-0.3907815631262528,-0.3707414829659319,-0.350701402805611,-0.330661322645291,-0.31062124248497014,-0.29058116232464926,-0.27054108216432926,-0.2505010020040084,-0.2304609218436875,-0.2104208416833666,-0.19038076152304662,-0.17034068136272573,-0.15030060120240485,-0.13026052104208397,-0.11022044088176397,-0.09018036072144309,-0.0701402805611222,-0.05010020040080221,-0.030060120240481325,-0.010020040080160442,0.010020040080160442,0.030060120240480437,0.05010020040080132,0.0701402805611222,0.09018036072144309,0.11022044088176308,0.13026052104208397,0.15030060120240485,0.17034068136272484,0.19038076152304573,0.2104208416833666,0.2304609218436875,0.2505010020040075,0.2705410821643284,0.29058116232464926,0.31062124248497014,0.33066132264529013,0.350701402805611,0.3707414829659319,0.3907815631262519,0.4108216432865728,0.43086172344689366,0.45090180360721455,0.47094188376753454,0.4909819639278554,0.5110220440881763,0.5310621242484972,0.5511022044088172,0.5711422845691381,0.591182364729459,0.611222444889779,0.6312625250500998,0.6513026052104207,0.6713426853707416,0.6913827655310616,0.7114228456913825,0.7314629258517034,0.7515030060120242,0.7715430861723442,0.7915831663326651,0.811623246492986,0.831663326653306,0.8517034068136269,0.8717434869739478,0.8917835671342687,0.9118236472945886,0.9318637274549095,0.9519038076152304,0.9719438877755513,0.9919839679358713,1.0120240480961922,1.032064128256513,1.052104208416833,1.072144288577154,1.0921843687374748,1.1122244488977957,1.1322645290581157,1.1523046092184366,1.1723446893787575,1.1923847695390783,1.2124248496993983,1.2324649298597192,1.25250501002004,1.27254509018036,1.292585170340681,1.3126252505010019,1.3326653306613228,1.3527054108216428,1.3727454909819636,1.3927855711422845,1.4128256513026045,1.4328657314629254,1.4529058116232463,1.4729458917835672,1.4929859719438872,1.513026052104208,1.533066132264529,1.5531062124248498,1.5731462925851698,1.5931863727454907,1.6132264529058116,1.6332665330661316,1.6533066132264524,1.6733466933867733,1.6933867735470942,1.7134268537074142,1.733466933867735,1.753507014028056,1.7735470941883769,1.7935871743486969,1.8136272545090177,1.8336673346693386,1.8537074148296586,1.8737474949899795,1.8937875751503004,1.9138276553106213,1.9338677354709413,1.9539078156312621,1.973947895791583,1.993987975951904,2.014028056112224,2.034068136272545,2.0541082164328657,2.0741482965931857,2.0941883767535066,2.1142284569138274,2.1342685370741483,2.1543086172344683,2.174348697394789,2.19438877755511,2.214428857715431,2.234468937875751,2.254509018036072,2.2745490981963927,2.2945891783567127,2.3146292585170336,2.3346693386773545,2.3547094188376754,2.3747494989979954,2.3947895791583163,2.414829659318637,2.434869739478958,2.454909819639278,2.474949899799599,2.49498997995992,2.5150300601202398,2.5350701402805607,2.5551102204408815,2.5751503006012024,2.5951903807615224,2.6152304609218433,2.635270541082164,2.655310621242485,2.675350701402805,2.695390781563126,2.715430861723447,2.735470941883767,2.7555110220440877,2.7755511022044086,2.7955911823647295,2.8156312625250495,2.8356713426853704,2.8557114228456912,2.875751503006012,2.895791583166332,2.915831663326653,2.935871743486974,2.955911823647294,2.9759519038076148,2.9959919839679356,3.0160320641282556,3.0360721442885765,3.0561122244488974,3.0761523046092183,3.096192384769539,3.11623246492986,3.136272545090179,3.1563126252505,3.176352705410821,3.196392785571142,3.2164328657314627,3.2364729458917836,3.2565130260521045,3.2765531062124253,3.2965931863727445,3.3166332665330653,3.336673346693386,3.356713426853707,3.376753507014028,3.396793587174349,3.4168336673346698,3.436873747494989,3.4569138276553097,3.4769539078156306,3.4969939879759515,3.5170340681362724,3.5370741482965933,3.557114228456914,3.5771543086172333,3.597194388777554,3.617234468937875,3.637274549098196,3.657314629258517,3.6773547094188377,3.6973947895791586,3.7174348697394795,3.7374749498997986,3.7575150300601194,3.7775551102204403,3.797595190380761,3.817635270541082,3.837675350701403,3.857715430861724,3.877755511022043,3.897795591182364,3.9178356713426847,3.9378757515030056,3.9579158316633265,3.9779559118236474,3.9979959919839683,4.018036072144287,4.038076152304608,4.058116232464929,4.07815631262525,4.098196392785571,4.118236472945892,4.138276553106213,4.158316633266534,4.178356713426853,4.1983967935871735,4.218436873747494,4.238476953907815,4.258517034068136,4.278557114228457,4.298597194388778,4.318637274549097,4.338677354709418,4.358717434869739,4.37875751503006,4.398797595190381,4.4188376753507015,4.438877755511022,4.4589178356713415,4.478957915831662,4.498997995991983,4.519038076152304,4.539078156312625,4.559118236472946,4.579158316633267,4.599198396793588,4.619238476953907,4.639278557114228,4.6593186372745485,4.679358717434869,4.69939879759519,4.719438877755511,4.739478957915832,4.759519038076151,4.779559118236472,4.799599198396793,4.819639278557114,4.839679358717435,4.859719438877756,4.8797595190380765,4.899799599198396,4.9198396793587165,4.939879759519037,4.959919839679358,4.979959919839679,5.0],"y":[-0.03346425462142428,-0.03400019923243811,-0.034544073747888863,-0.0350959777650437,-0.03565601160710965,-0.036224276310250735,-0.03680087360975027,-0.03738590592528926,-0.03797947634531064,-0.038581688610438904,-0.03919264709592328,-0.03981245679307222,-0.04044122328964558,-0.041079052749170834,-0.04172605188914828,-0.04238232795810891,-0.043047988711488856,-0.043723142386282346,-0.0444078976744349,-0.04510236369493676,-0.045806649964576736,-0.04652086636731472,-0.04724512312223028,-0.047979530750004426,-0.04872420003788979,-0.04947924200312417,-0.050244767854740434,-0.05102088895372611,-0.051807716771483575,-0.052605362846541694,-0.05341393873946776,-0.05423355598592878,-0.055064326047848784,-0.05590636026260865,-0.05675976979023314,-0.057624665558509515,-0.05850115820598066,-0.05938935802275381,-0.06028937488906644,-0.06120131821154836,-0.06212529685711884,-0.06306141908445556,-0.06400979247297252,-0.06497052384924171,-0.06594371921079245,-0.06692948364722207,-0.06792792125854956,-0.06893913507074372,-0.06996322694835487,-0.07100029750418044,-0.07205044600589144,-0.0731137702795478,-0.07419036660992774,-0.07528032963759784,-0.07638375225264725,-0.07750072548501025,-0.07863133839129992,-0.0797756779380754,-0.0809338288814641,-0.08210587364305988,-0.0832918921820176,-0.08449196186326423,-0.0857061573217458,-0.0869345503226294,-0.08817720961737932,-0.08943420079562633,-0.09070558613274808,-0.09199142443308005,-0.09329177086867557,-0.09460667681353425,-0.09593618967321767,-0.09728035270977269,-0.09863920486188309,-0.10001278056016995,-0.10140110953756361,-0.10280421663467017,-0.1042221216000568,-0.1056548388853816,-0.10710237743529531,-0.10856474047204405,-0.11004192527470393,-0.1115339229529806,-0.11304071821550922,-0.11456228913259338,-0.11609860689332326,-0.11764963555701723,-0.11921533179893481,-0.12079564465021128,-0.12239051523196899,-0.12399987648356468,-0.12562365288493635,-0.12726176017301805,-0.12891410505219594,-0.13058058489878502,-0.13226108745951157,-0.13395549054399195,-0.13566366171120572,-0.13738545794996837,-0.13912072535341496,-0.14086929878751525,-0.14263100155364825,-0.14440564504527342,-0.14619302839874435,-0.1479929381383207,-0.14980514781544438,-0.15162941764235618,-0.15346549412014035,-0.15531310966129663,-0.1571719822069504,-0.15904181483882524,-0.1609222953861154,-0.1628130960274079,-0.16471387288782105,-0.16662426563153807,-0.1685438970499326,-0.17047237264549647,-0.17240928021179927,-0.17435418940972378,-0.1763066513402418,-0.17826619811401076,-0.18023234241809213,-0.18220457708011206,-0.18418237463020304,-0.1861651868610891,-0.1881524443866947,-0.1901435561996825,-0.19213790922834476,-0.19413486789329795,-0.19613377366445214,-0.19813394461875117,-0.20013467499920315,-0.2021352347757462,-0.2041348692085188,-0.20613279841412951,-0.20812821693554676,-0.2101202933162546,-0.21210816967934798,-0.21409096131226507,-0.21606775625788305,-0.2180376149127287,-0.21999956963308204,-0.22195262434977808,-0.2238957541925375,-0.2258279051246838,-0.2277479935891293,-0.22965490616654016,-0.23154749924661103,-0.23342459871341112,-0.2352849996457799,-0.23712746603378024,-0.23895073051223412,-0.24075349411239108,-0.24253442603279646,-0.24429216343044863,-0.24602531123334964,-0.24773244197557143,-0.24941209565597414,-0.2510627796217253,-0.2526829684777819,-0.25427110402350317,-0.25582559521757336,-0.2573448181724145,-0.258827116179274,-0.2602707997651719,-0.2616741467828883,-0.26303540253516744,-0.2643527799343054,-0.2656244596982778,-0.2668485905845468,-0.2680232896626718,-0.2691466426268229,-0.2702167041492734,-0.2712314982759166,-0.2721890188648206,-0.2730872300687967,-0.2739240668629158,-0.2746974356178628,-0.27540521471996826,-0.27604525523870377,-0.27661538164236843,-0.2771133925626311,-0.2775370616085263,-0.2778841382304304,-0.2781523486344669,-0.2783393967477116,-0.2784429652344805,-0.27846071656389737,-0.2783902941288408,-0.27822932341627554,-0.27797541322886926,-0.2776261569576917,-0.2771791339056815,-0.276631910661455,-0.2759820425229141,-0.2752270749699892,-0.2743645451857331,-0.2733919836248553,-0.2723069156286582,-0.2711068630852087,-0.26978934613344663,-0.26835188490979905,-0.2667920013357375,-0.26510722094458034,-0.2632950747457089,-0.2613531011242339,-0.2592788477740152,-0.2570698736618078,-0.254723751020177,-0.25223806736669996,-0.2496104275468472,-0.24683845579781585,-0.24391979783047174,-0.24085212292644367,-0.23763312604731002,-0.2342605299527109,-0.230732087324128,-0.22704558289098647,-0.22319883555564654,-0.21918970051378403,-0.21501607136658885,-0.2106758822211584,-0.20616710977540667,-0.20148777538377827,-0.19663594710002227,-0.19160974169326514,-0.18640732663360843,-0.1810269220434822,-0.17546680261099865,-0.16972529946156795,-0.16380080198408037,-0.15769175960799792,-0.15139668352776428,-0.14491414837099983,-0.13824279380703786,-0.13138132609244313,-0.12432851955026142,-0.11708321797985394,-0.10964433599429974,-0.10201086028248488,-0.09418185079313049,-0.0861564418381768,-0.07793384311309225,-0.06951334063185749,-0.06089429757453972,-0.052076155045570956,-0.04305843274102672,-0.03384072952341093,-0.024422723902643117,-0.014804174422163358,-0.004984919949284474,0.005035120130875968,0.015255945818317506,0.025677476498158623,0.036299551037711264,0.047121927980416374,0.05814428583619252,0.06936622346754424,0.08078726057054736,0.09240683824963297,0.10422431968486927,0.11623899089023612,0.12845006156120262,0.1408566660097081,0.15345786418447477,0.16625264277438787,0.179239916392527,0.19241852883825256,0.2057872544346112,0.21934479943816762,0.23308980351825426,0.2470208413024927,0.2611364239853257,0.27543500099621593,0.2899149617240526,0.3045746372942472,0.3194123023949112,0.3344261771484749,0.34961442902503914,0.3649751747937314,0.38050648250830055,0.3962063735231903,0.412072824536316,0.42810376965477415,0.44429710247975507,0.4606506782069338,0.47716231573867174,0.4938297998043933,0.5106508830855806,0.5276232883418727,0.5447447105348492,0.5620128189461387,0.5794252592866062,0.5969796557934499,0.61467361331214,0.6325047193602534,0.6504705461703548,0.6685686527092007,0.6867965866706501,0.7051518864398137,0.7236320830260723,0.7422347019627455,0.7609572651713044,0.7797972927881749,0.7987523049522987,0.8178198235517418,0.8369973739278065,0.8562824865352016,0.8756726985569816,0.8951655554730761,0.9147586125813866,0.934449436470529,0.9542356064434439,0.9741147158911992,0.9940843736164627,1.0141422051062006,1.0342858537532902,1.054512982026856,1.0748212725912123,1.0952084293734374,1.1156721785796533,1.136210269660236,1.1568204762242216,1.177500596903278,1.1982484561657045,1.2190619050809712,1.2399388220354113,1.2608771133997083,1.2818747141489333,1.3029295884358962,1.3240397301186677,1.3452031632431396,1.3664179424815848,1.3876821535281747,1.408993913452468,1.4303513710119269,1.4517527069245257,1.4731961341025632,1.4946798978487819,1.5162022760159621,1.5377615791311234,1.5593561504855147,1.5809843661915568,1.602644635207933,1.6243353993340053,1.6460551331747288,1.6678023440772716,1.6895755720404928,1.7113733895984655,1.7331944016791918,1.7550372454396699,1.7769005900784436,1.798783136626765,1.8206836177194547,1.8426007973465748,1.8645334705869665,1.886480463324698,1.9084406319494644,1.9304128630419308,1.952396073045011,1.974389207922028,1.9963912428027022,2.0184011816178677,2.040418056723807,2.0624409285170446,2.084468885040458,2.106501041581487,2.1285365402632253,2.1505745496291566,2.172614264222249,2.194654904159113,2.216695714699886,2.238735965814506,2.2607749517459803,2.282811990571254,2.3048464237602375,2.326877615733545,2.3489049534194715,2.370927845810679,2.3929457235210903,2.41495803834343,2.4369642628078325,2.458963889741922,2.480956431832761,2.5029414211910055,2.5249184089176295,2.546886964673514,2.5688466762522286,2.5907971491562667,2.612738006177001,2.6346688869786137,2.6565894476862244,2.67849936047842,2.7003983131843947,2.722286008885872,2.744162165523976,2.766026515511209,2.7878788053486536,2.8097187952485494,2.8315462587623417,2.853360982414287,2.8751627653407406,2.8969514189351613,2.918726766498929,2.9404886428980124,2.9622368942255473,2.9839713774703482,3.005691960191394,3.0273985201983042,3.0490909452378028,3.0707691326862054,3.092432989247898,3.1140824306598147,3.1357173814018937,3.1573377744134907,3.1789435508157275,3.200534659639742,3.222111057560793,3.243672708638198,3.2652195840610476,3.286751661899645,3.308268926862626,3.329771370059693,3.3512589887699282,3.372731786215574,3.394189771341281,3.4156329585987084,3.437061367736424,3.4584750235950312,3.4798739559074603,3.501258199104336,3.5226277921243407,3.5439827782295206,3.565323204825437,3.5866491232860898,3.607960588783532,3.6292576601220996,3.6505403995771686,3.671808872738373,3.6930631483571763,3.7143032981987436,3.7355293968980217,3.7567415218199387,3.7779397529236483,3.7991241726307434,3.8202948656973534,3.8414519190900376,3.8625954218654077,3.8837254650533986,3.9048421415441,3.925945545978077,3.947035774640107,3.968112925356253,3.989177097394185,4.0102283913667005,4.031266909138349,4.052292753735099,4.073306029256971,4.0943068407935606,4.115295294342396,4.136271496730055,4.157235555535946,4.178187579018749,4.199127676045383,4.220055956022477,4.240972528830269,4.261877504758864,4.282770994446809,4.30365310882189,4.324523959044131,4.345383656450913,4.36623231250416,4.387070038739539,4.4078969467176154,4.4287131479769215,4.449518753988858,4.470313876114414,4.49109862556262,4.511873113350716,4.532637450265953,4.553391746829011,4.5741361132589695,4.594870659439793,4.615595494888266,4.63631072872338,4.657016469637082,4.677712825866363,4.698399905166662,4.719077814786506,4.7397466614434,4.7604065513008695,4.781057589946675,4.801699882372125,4.822333532952467,4.842958645428326,4.863575322888145,4.884183667751607,4.904783781753994,4.925375765931469,4.945959720607241,4.966535745378576],"type":"scatter","xaxis":"x3","yaxis":"y3"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,0.2888888888888889]},"yaxis":{"anchor":"x","domain":[0.0,1.0]},"xaxis2":{"anchor":"y2","domain":[0.35555555555555557,0.6444444444444445]},"yaxis2":{"anchor":"x2","domain":[0.0,1.0]},"xaxis3":{"anchor":"y3","domain":[0.7111111111111111,1.0]},"yaxis3":{"anchor":"x3","domain":[0.0,1.0]},"annotations":[{"font":{"size":16},"showarrow":false,"text":"ELU","x":0.14444444444444446,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"GELU","x":0.5,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"SiLU","x":0.8555555555555556,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"}],"title":{"text":"Other Activation Functions"},"height":400,"width":900,"showlegend":false},                        {"responsive": true}                    )                };                            </script>        </div>

<h2 id="weight-initializations">Weight Initializations</h2>
<ol>
<li>Values too small: All activations tend to zero for deeper network layers</li>
<li>Values too large: Activations blow up quickly</li>
</ol>
<h3 id="kaiming-msra-initialization">Kaiming / MSRA Initialization</h3>
<p>(Specially designed for ReLU).</p>
<div class="arithmatex">\[
W \sim \mathcal{N}\left(0, \frac{2}{n}\right)
\]</div>
<p>or </p>
<div class="arithmatex">\[
W \sim \mathcal{U}\left(-\sqrt{\frac{6}{n}}, \sqrt{\frac{6}{n}}\right)
\]</div>
<h2 id="data-processing">Data Processing</h2>
<h3 id="tldr-for-image-normalization">TLDR for Image Normalization</h3>
<ul>
<li>Subtract per-channel mean and divide by per-channel std</li>
<li>Requires pre-computing means and std for each pixel channel (given your dataset)</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="n">norm_pixel</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pixel</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pixel</span><span class="p">[:,</span> <span class="p">:,</span><span class="n">c</span><span class="p">]))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">pixel</span><span class="p">[:,:,</span><span class="n">c</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<h2 id="data-augmentation">Data augmentation</h2>
<ul>
<li>Dropout (Add some randomness and average them when testing)</li>
<li>Horizontal flips and random crops and scales (for figures)</li>
<li>Color jitter (Randomize brightness and contrast)</li>
<li>Cut out (Set some random regions of an image to zero when training and use full picture when testing)</li>
</ul>
<h2 id="transfer-learning">Transfer Learning</h2>
<p>A way to train with a small amount of data. Just use the pretrained model of other image classifier and simpoly retrain the classifier layer for new dataset/</p>
<div class="admonition remarks">
<p class="admonition-title">Remarks</p>
<p>It's a norm for image networks nowadays!</p>
</div>
<h2 id="hyperparameter-selection">Hyperparameter Selection</h2>
<p>Take Learning rate for example.</p>
<ol>
<li>Check initial loss</li>
<li>Overfit a small sample</li>
<li>Find LR that makes loss go down</li>
<li>Coarse grid, train for ~1-5 epochs</li>
<li>Refine grid, train longer</li>
<li>Look at loss and accuracy curves</li>
<li>GOTO step 5</li>
</ol>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2025年7月30日 14:51:48 UTC">2025-07-30</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2025年7月23日 13:51:20 UTC">2025-07-23</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../../Gradient_Descent/Gradient_Descent/" class="md-footer__link md-footer__link--prev" aria-label="上一页: Gradient Descent">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Gradient Descent
              </div>
            </div>
          </a>
        
        
          
          <a href="../../RNN/RNN/" class="md-footer__link md-footer__link--next" aria-label="下一页: RNN">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                RNN
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/Abiesjqq" target="_blank" rel="noopener" title="Abies on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/Noflowerzzk" target="_blank" rel="noopener" title="Noflower on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["announce.dismiss", "navigation.instant", "header.autohide", "navigation.instant.progress", "navigation.prune", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "toc.follow", "navigation.indexes", "content.tabs.link", "content.tooltips", "content.code.copy", "content.code.select", "content.code.annotate", "git-revision-date", "git-revision-date-localized"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/gh/Wcowin/Wcowin.github.io@main/docs/javascripts/extra.js"></script>
      
        <script src="../../../../javascripts/animate-details.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="../../../../javascripts/cursor.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../../../javascripts/busuanzi.pure.mini.js"></script>
      
        <script src="https://cdn.jsdelivr.net/gh/Wcowin/Wcowin.github.io@main/docs/javascripts/view.js"></script>
      
    
  </body>
</html>