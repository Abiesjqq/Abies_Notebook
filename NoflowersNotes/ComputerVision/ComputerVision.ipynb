{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CS231n: Deep Learning for Computer Vision\n",
    "## Stanford - Spring 2025\n",
    "\n",
    "### Image Classification\n",
    "\n",
    "#### Ways to compare images\n",
    "\n",
    "- L1 distances: $d_1(I_1, I_2) = \\sum_p \\vert I_1^p - I_2^p \\vert$\n",
    "- L2 distances: $d_2(I_1, I_2) = \\sqrt{\\sum_p \\vert I_1^p - I_2^p \\vert^2}$\n",
    "\n",
    "A classifier below with $O(1)$ for training and $O(N)$ for predecting with L1 distance.\n"
   ],
   "id": "7d15a356b31c92a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighbor(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def train(self, X, y):\n",
    "    \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
    "    # the nearest neighbor classifier simply remembers all the training data\n",
    "    self.Xtr = X\n",
    "    self.ytr = y\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
    "    num_test = X.shape[0]\n",
    "    # let's make sure that the output type matches the input type\n",
    "    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
    "\n",
    "    # loop over all test rows\n",
    "    for i in range(num_test):\n",
    "      # find the nearest training image to the i'th test image\n",
    "      # using the L1 distance (sum of absolute value differences)\n",
    "      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
    "      min_index = np.argmin(distances) # get the index with the smallest distance\n",
    "      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example\n",
    "\n",
    "    return Ypred"
   ],
   "id": "21f6f4a8cf67251c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It's bad: we want classifiers that are fast at prediction and slow for training\n",
    "\n",
    "#### K-Neatest Neighbours\n",
    "The idea is very simple: instead of finding the single closest image in the training set, we will find the top k closest images, and have them vote on the label of the test image.\n",
    "Higher values of k have a smoothing effect that makes the classifier more resistant to outliers\n",
    "\n",
    "![K-NN.png](./resources/NNClassifier.png)\n"
   ],
   "id": "7a1e4442c2c96bc7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
