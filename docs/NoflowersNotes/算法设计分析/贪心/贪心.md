
## Hard Problem

**The Partition Problem**: Get a partition of num-set $S$ such that $\sum_{S_1}x = \sum_{S_2}x$ --> NP hard. (Proof later)

"Homework ++": given a set of tasks with release time $r_i$, duration $s_i$ and DDL $d_i$, find a arrangement to complete them.

!!! remarks "Prove Homework ++ is harder than partition"
    Given the partition input $\{a_1, \ldots, a_n\}$, let $w = \sum a_i$  
    $n + 1$ homeworks, the first $n$ represents $a_1, \ldots, a_n$, each has release time $0$, DDL $w + 1$, and size $a_i$.  
    And the last homework has release time $w / 2$, DDL $w / 2 + 1$ and size $1$, so it must start at time $w / 2$.  
    Then the arrangement of the other tasks is a partition problem!

## Minimum Spanning Tree (MST)

Definition and algorithms were introduced in discrete math, omitted.

The following algorithms are available for undirected graphs!

### Prim Algorithm

Add a node into the tree each time. Exactly, from a vertex, add a node into the tree with the closest edge weight.

```
# Initialize
T = {}, S = {}
cost[r] = 0, cost[v] = inf for v other than r
for r's neighbour v: cost[v] = w(r, v), pre[v] = r

# Recurse
while:
    find v not in S with smallest cost[v]
    S = S + {v}, T = T + {(pre[v], v)}
    
    # update
    for v's neighbour u:
        cost[u] = min(cost[u], w(u, v))
        if cost[u] was updated, pre[u] = v
```

With Fibonacci heap, we have $O(\vert E \vert + \vert V \vert \log \vert V \vert)$

### Kruskal's Algorithm

Add an edge between the vertices each time. Exactly, sorting the edges and choose a shortest edge which will not form a cycle and add it into the tree edges.

To simplify the process of detecting cycle-formation, we utilize **union-find set**

```
sort(E, ascending)

for each u, create a group containing only u

for each (u, v) in E with ascending order:
    if root(u) ≠ root(v):
        add (u, v) into the MST
        union(u, v)
```

!!! remarks "Union-Find"
    Create: $O(1)$  
    Find: $O(\log n)$  
    Union: $O(1)$

    So for Kruskal,  
    Sorting: $O(\vert E \vert \log \vert E \vert)$  
    Create and Union: $O(\vert V \vert)$  
    Find: $O(\vert E \vert)$  

    !!! normal-comment "Why $O(\log n)?$"
        Record the tree height, and when union, merge short tree to high tree.  
        By this, the tree of height $k$ (`rank[i]`) will cost about $2^k$ nodes. --> Union with rank (按秩合并)

    !!! remarks "Refine with path compression"

        Amortized analysis, we'll prove:  
        $m$ FIND ops take total time $O(m \log^* n + n \log^* m)$

        At each FIND, we will **cut** some edges (and connect them to the same root), and the edges connecting directly to root is **uncut**.  
        We can easily know that cost of FIND ($m$ times) through the uncut edges is $O(m)$

        The FIND and path compression will not change `rank[v]`, so it is no longer the height of the subtree rooted at `v`. However, these properties still holds:  
        - Parent’s rank is strictly larger than the child’s.  
        - Ranks never decrease.  
        - Rank increments only happen at the root nodes.  
    
        Now, (in analysis) group the nodes by ranks:
    
        $$
        \begin{cases}
        g_i &= \{v_i\ |\ \mathrm{rank}[v_i] \in [k_i + 1, 2^{k_i}] \} \\
        k_{i + 1} &= 2^{k_i}
        \end{cases}
        $$
    
        then we divide the whole $n$ data into $\log^* n$ groups!
        
        We divide the charging of FIND into twe kinds:  
        - **Same Group Charging (SGC)**: Cut from a parent with the same rank-group  
        - **Across Group Charging (AGC)**: Cut from a parent with a different rank-group  
    
        **AGC**
        
        There are at most $\log^* n$ AGCs in a FIND, so in $m$ FINDs, the cost is $m \log^*n$
        
        **SGC**
        
        At each SGC for a $v \in [k_i + 1, 2^{k_i}]$, the parent of $v$'s rank will strictly increase. And there is at most $2^{k_i} - (k_i + 1) < 2^{k_i}$ SGC for $v$.  
        Also, in such group, there is at most $n / 2^{k_i}$ vertices (it requires $2^{k_i}$ vertices to build a rank $k_i$ tree!). So considering all the vertices, there are at most $n / 2^{k_i} \cdot 2^{k_i}$ SGCs.  
        So for total $\log^* n$ groups, $m$ FINDs will cost $n \log^* n$.
        
        In conclusion, the total time is $m + m \log^* n + n \log^* n$ (_uncut + AGC + SGC_)  
        And let $m \to \infty$, time complexity will be $O(m \log^* n)$.

## Greedy-Based Approximation Algorithms

The greedy approach give a reliable approximation for some difficult problems.

Consider a minimization problem and an algorithm $\mathcal{A}$ for it. Let $\mathcal{A}(I)$ be the value output by $\mathcal{A}$ given input $I$. Let $\mathrm{OPT}(I)$ be the optimal solution for $I$. $\mathcal{A}$ is an **$\alpha$-approximation algorithm** if  

$$
\forall I:\quad \frac{\mathcal{A}(I)}{\mathrm{OPT}(I)} \le \alpha
$$

For a maximization problem, $\mathcal{A}$ is an **$\alpha$-approximation algorithm** if  

$$
\forall I:\quad \frac{\mathcal{A}(I)}{\mathrm{OPT}(I)} \ge \alpha
$$

### Max-k-coverage and Set Cover Problems

Let $U = \langle n \rangle$ be a ground set of elements, and give $T = \{A_1, \ldots, a_m\}$ be a collection of subsets of $U$ with $\bigcup_{A_i \in T}A_i = U$.

**Set Cover**: Find a subcollection $S \subseteq T$ with minimum $\vert S \vert$ such that $\bigcup_{A_i \in S}A_i = U$  
**Max-k-coverage**: Find a subcollection $S \subseteq T$ with $\vert S \vert \leq k$ that maximizes $\left\vert \bigcup_{A_i \in S}A_i \right\vert$

~~They are all NP-Hard!~~

!!! normal-comment "We can describe subsets and elements with bipartite graph!"

Denote $f(S) = \left\vert \bigcup_{A_i \in S}A_i \right\vert$

```
Initialize S = ∅
repeat:
    find A ∈ T \ S that maximizes f(S ∪ {A}) - f(S)
    update S = S ∪ {A}
until:
    f(S) = |U| (for set cover)
    |S| = k    (for max-k-coverage)
```

!!! remarks "Analysis"

    Let $S^* = \{O_1, \ldots, O_k\}$ be any collection of $k$ subsets, $S = \{A_1, \ldots, A_l\}$ be the output of the algorithm after $l$ iterations.  We gonna prove that
    
    $$
    f(S) \geq \left(1 - \left(1 - \frac{1}{k}\right)^l\right)f(S^*) \geq \left(1 - \frac{1}{\mathrm{e}}\right) f(S^*)
    $$
    
    which gives the lower bound for max-k-coverage.  
    And for $\vert S^* \vert = k$ and if we let $l = k\ln n$, we have
    
    $$
    f(S) \geq \left(1 - \left(1 - \frac{1}{k}\right)^{k \ln n}\right)f(S^*) > \left(1 - \frac{1}{\mathrm{e^{\ln n}}}\right) f(S^*) = n - 1 \Rightarrow f(S) = n
    $$
    
    which gives a $\ln n$ approximation.
    
    Proof by inductive: Let $S_t = \{A_1, \ldots, A_t\}, t = 1, 2, \ldots, l$.  
    $l = 1$, by greedy nature, $f(S_1 = \{A_1\}) \geq f(O_i)$ for all $O_i$, thus, 
    
    $$
    f(S_1) \geq \frac{1}{k}\sum_{k = 1}^{l}f\left(\{O_i\}\right) \geq \frac{1}{k}f(S^*) = \left(1 - \left(1 - \frac{1}{k}\right)^{1}\right)f(S^*)
    $$
    
    Now $S_t$ after $t$ iterations, consider $\Delta(O_i\vert S_t) = f(S_t \cup \{O_i\}) - f(S_t)$. By greedy nature, $\Delta(A_{t + 1}\vert S_t) \geq \Delta(O_i\vert S_t)$. Also we have
    
    $$
    \begin{align}
    &\Delta(A_{t + 1}\vert S_t) \geq \frac{1}{k}\sum_{k = 1}^{l}\Delta(O_i\vert S_t) \geq \frac{1}{k}\Delta(S^*\vert S_t) \\
    \Leftrightarrow& f(S_{t + 1}) - f(S_t) \geq \frac{1}{k}\left(f(S^* \cup S_t) - f(S_t)\right) \geq \frac{1}{k}\left(f(S^*) - f(S_t)\right) \\
    \Leftrightarrow& f(S_{t + 1}) \geq \frac{1}{k}f(S^*) + \left(1 - \frac{1}{k}\right)f(S_t)  \\ &= \left(1 - \left(1 - \frac{1}{k}\right)^{t + 1}\right)f(S^*)
    \end{align}
    $$

!!! remarks "Are we doing the best in poly-time?"
    we can note that all the equations above is tight (Roughly)  
    Actually, no $\displaystyle 1 - \frac{1}{\mathrm{e}} + \varepsilon$-approx algorithm unless **P = NP**

### Facility Location

#### $k$-centers

Build $k$ facilities, and minimize the maximum distance between any vertex to its closest facility. (Especially in a metric space (度量空间))

Input a metric space (always a undirected graph with triangle inequality) and $k$, output the $k$ center choices and $S \subseteq V$ which minimizes

$$
f(S) = \max_{v \in V} \min_{s \in S} d(S, V)
$$

it has a $2$-approx: iteratively pick the center farthest to the existing centers  

!!! remarks "Analysis"
    Let $O = \{o_1, \ldots, o_k\}$ be the optimal solution with cost $\mathrm{OPT}$  
    Let $A = \{a_1, \ldots, a_k\}$ be the algorithm’s output with cost $\mathrm{ALG}$  
    The theorem says $\mathrm{ALG} \leq 2 \cdot \mathrm{OPT}$
    
    For each $o_i$, let $X_i$ be the set of vertices closest to $o_i$ (their "min" is calculated by the dist to $o_i$). $\{X_1, \ldots, X_k\}$ is a partition of $V$. (Voronoi area)  
    Denote $d(A, v) = \min_{a \in A}d(a, v)$
    
    **Case 1.** $A \cap X_i \neq \emptyset$ for all $i$ (1), then obviously each $X_i$ contain a center in $A$. WLOG assume $a_i \in X_i$.
    { .annotate}
    
    1. Noting that **each** $X_i$ is a set.
    
    Considering any $v \in V$, assume $v \in X_i$. Then $d(a_i, v) \leq d(a_i, o_i) + d(o_i, v) \leq 2 \cdot \mathrm{OPT}$.  
    In the algorithm $v$ is assigned to $a'$, then $d(a', v) \leq d(a_i, v) \leq 2 \cdot \mathrm{OPT}$. So $\mathrm{ALG} = \min_{v \in V}d(a', v) \leq 2 \cdot \mathrm{OPT}$
    
    **Case 2** $A \cap X_i = \emptyset$ for some $i$.  

    So some $X_i$ contains two centers in $A$. Suppose $a_j, a_r \in X_i$, and $a_j$ was chosen earlier by the algorithm. So at the time $a_r$ was add to $A$, $\mathrm{ALG} \leq d(A, a_r) \leq d(a_j, a_r)$.  
    Noting that $a_j, a_r \in X_i$, $d(a_j, a_r) \leq d(a_j, o_i) + d(a_r, o_i) \leq 2 \cdot \mathrm{OPT}$  
    So we also have $\mathrm{ALG} \leq 2 \cdot \mathrm{OPT}$

    !!! normal-comment "When to get "="?"
        $V$ forms a **line** and $k = 2$, in ALG we choose the mid point and the endpoint --> $\vert V \vert / 2$, but if we choose quarter points, the OPT will be $\vert V \vert / 4$

Actually, no $(2 - \varepsilon)$-approx poly-algorithm exists.  

!!! remarks "Dominating Set Problem"
    Given an undirected graph $G = (V, E)$, a dominating set is a subset of vertices $S$ such that, for any $v \in V \backslash S$, there is a vertex $u \in S$ that is adjacent to $v$.

    **Dominating Set Problem** Given a graph $G$ and a integer $k$, decide if $G$ contains a dominating set with size $k$. It is know as an NP-Hard problem.

!!! normal-comment "Prove no $(2 - \varepsilon)$-approx poly-algorithm exists"
    If we have, denote it by $\mathcal{A}$. Given a dominating set graph $G$, for all $k$, if the output of $\mathcal{A}$ on $G$ is $1$, then $G$ has a dominating set! (Due to having a dominating set iff $\mathrm{OPT} = 1 \Leftrightarrow \mathrm{OPT} \leq \mathrm{ALG} \leq (2 - \varepsilon)\cdot\mathrm{OPT} < 2 \Leftrightarrow \mathrm{ALG} = 1$)


    


