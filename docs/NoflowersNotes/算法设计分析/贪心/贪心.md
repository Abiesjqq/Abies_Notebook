
## Hard Problem

**The Partition Problem**: Get a partition of num-set $S$ such that $\sum_{S_1}x = \sum_{S_2}x$ --> NP hard. (Proof later)

"Homework ++": given a set of tasks with release time $r_i$, duration $s_i$ and DDL $d_i$, find a arrangement to complete them.

!!! remarks "Prove Homework ++ is harder than partition"
    Given the partition input $\{a_1, \ldots, a_n\}$, let $w = \sum a_i$  
    $n + 1$ homeworks, the first $n$ represents $a_1, \ldots, a_n$, each has release time $0$, DDL $w + 1$, and size $a_i$.  
    And the last homework has release time $w / 2$, DDL $w / 2 + 1$ and size $1$, so it must start at time $w / 2$.  
    Then the arrangement of the other tasks is a partition problem!

## Minimum Spanning Tree (MST)

Definition and algorithms were introduced in discrete math, omitted.

The following algorithms are available for undirected graphs!

### Prim Algorithm

Add a node into the tree each time. Exactly, from a vertex, add a node into the tree with the closest edge weight.

```
# Initialize
T = {}, S = {}
cost[r] = 0, cost[v] = inf for v other than r
for r's neighbour v: cost[v] = w(r, v), pre[v] = r

# Recurse
while:
    find v not in S with smallest cost[v]
    S = S + {v}, T = T + {(pre[v], v)}
    
    # update
    for v's neighbour u:
        cost[u] = min(cost[u], w(u, v))
        if cost[u] was updated, pre[u] = v
```

With Fibonacci heap, we have $O(\vert E \vert + \vert V \vert \log \vert V \vert)$

### Kruskal's Algorithm

Add an edge between the vertices each time. Exactly, sorting the edges and choose a shortest edge which will not form a cycle and add it into the tree edges.

To simplify the process of detecting cycle-formation, we utilize **union-find set**

```
sort(E, ascending)

for each u, create a group containing only u

for each (u, v) in E with ascending order:
    if root(u) ‚â† root(v):
        add (u, v) into the MST
        union(u, v)
```

!!! remarks "Union-Find"
    Create: $O(1)$  
    Find: $O(\log n)$  
    Union: $O(1)$

    So for Kruskal,  
    Sorting: $O(\vert E \vert \log \vert E \vert)$  
    Create and Union: $O(\vert V \vert)$  
    Find: $O(\vert E \vert)$  

    !!! normal-comment "Why $O(\log n)?$"
        Record the tree height, and when union, merge short tree to high tree.  
        By this, the tree of height $k$ (`rank[i]`) will cost about $2^k$ nodes. --> Union with rank (ÊåâÁß©ÂêàÂπ∂)

    !!! remarks "Refine with path compression"

        Amortized analysis, we'll prove:  
        $m$ FIND ops take total time $O(m \log^* n + n \log^* m)$

        At each FIND, we will **cut** some edges (and connect them to the same root), and the edges connecting directly to root is **uncut**.  
        We can easily know that cost of FIND ($m$ times) through the uncut edges is $O(m)$

        The FIND and path compression will not change `rank[v]`, so it is no longer the height of the subtree rooted at `v`. However, these properties still holds:  
        - Parent‚Äôs rank is strictly larger than the child‚Äôs.  
        - Ranks never decrease.  
        - Rank increments only happen at the root nodes.  
    
        Now, (in analysis) group the nodes by ranks:
    
        $$
        \begin{cases}
        g_i &= \{v_i\ |\ \mathrm{rank}[v_i] \in [k_i + 1, 2^{k_i}] \} \\
        k_{i + 1} &= 2^{k_i}
        \end{cases}
        $$
    
        then we divide the whole $n$ data into $\log^* n$ groups!
        
        We divide the charging of FIND into twe kinds:  
        - **Same Group Charging (SGC)**: Cut from a parent with the same rank-group  
        - **Across Group Charging (AGC)**: Cut from a parent with a different rank-group  
    
        **AGC**
        
        There are at most $\log^* n$ AGCs in a FIND, so in $m$ FINDs, the cost is $m \log^*n$
        
        **SGC**
        
        At each SGC for a $v \in [k_i + 1, 2^{k_i}]$, the parent of $v$'s rank will strictly increase. And there is at most $2^{k_i} - (k_i + 1) < 2^{k_i}$ SGC for $v$.  
        Also, in such group, there is at most $n / 2^{k_i}$ vertices (it requires $2^{k_i}$ vertices to build a rank $k_i$ tree!). So considering all the vertices, there are at most $n / 2^{k_i} \cdot 2^{k_i}$ SGCs.  
        So for total $\log^* n$ groups, $m$ FINDs will cost $n \log^* n$.
        
        In conclusion, the total time is $m + m \log^* n + n \log^* n$ (_uncut + AGC + SGC_)  
        And let $m \to \infty$, time complexity will be $O(m \log^* n)$.


!!! remarks "Matroid (ÊãüÈòµ) theorem and Independent sets (Áã¨Á´ãÈõÜ)"

    Consider a pair $M=(U,\mathcal{I})$ where $U$ is a finite set and $\mathcal{I}\subseteq \{0,1\}^U$ is a collection of subsets of $U$. We say $M$ is a _matroid_ if it satisfies:  
    1. **hereditary property**: $\mathcal{I}$ is nonempty and for every $A\in\mathcal{I}$ and $B\subseteq A$, it holds that $B\in\mathcal{I}$  
    2. **exchange property**: For any $A,B\in\mathcal{I}$ with $|A|<|B|$, there exists some $x\in B\setminus A$ such that $A\cup\{x\}\in\mathcal{I}$  
    Each set $A\in\mathcal{I}$ is called an _independent set_

    We have the property: Maximal independent sets are of the same size. (A set $A\in\mathcal{I}$ is _maximal_ if there is _no_ $B\in\mathcal{I}$ such that $A\subsetneq B$.)

    !!! examples "MST in matroid"

        Consider $G=(V,E)$, a simple undirected graph, let $M=(E,\mathcal{S})$ where $\mathcal{S}=\{F\subseteq E\mid F\text{ does not contain a cycle}\}$, $M$ is a **matroid**, all the acyclic subgraphs are **independent sets** and the **maximal independent sets** are all the spanning forests.

    Then we know that we can find a maximal independent set with the maximal weight (assign a non-negative weight for each element in set $U$) with Kruskal algorithm:

    ```
    S ‚Üê ‚àÖ
    Sort U in decreasing order by weight w

    for x ‚àà U (in decreasing order of w) do
        if S ‚à™ {x} ‚àà ùìò then
            S ‚Üê S ‚à™ {x}
        end if
    end for

    return S
    ```

    **Proof**: Obviously the $S$ is a maximal independent set.  
    Suppose $S = \{s_1, \ldots, s_n\}$ and there exists another maximal independent set $O = \{o_1, \ldots, o_n\}$ with larger weight. Let $k = \min_{\substack{l = 1, \ldots, n \\ s_l \neq o_l}}l$ (such $k$ must exist). Let $S_{k - 1} = \{s_1, \ldots, s_{k - 1}\}$ and $O_{k} = \{o_1, \ldots, o_k\}$, then according to exchange property, exists $o_p \in O_k \setminus S_{k - 1} (p \geq k)$, $S_{k - 1} \cup \{o_p\} \in \mathcal{I}$. $w(o_p) \geq w(o_k) > w(s_k)$. But the algorithm added $s_k$ instead of $o_p$ at the time $s_k$ was added, contradict to the descending order of the adding check!  
    So the algorithm output must be of the maximal weight.

## Greedy-Based Approximation Algorithms

The greedy approach give a reliable approximation for some difficult problems.

Consider a minimization problem and an algorithm $\mathcal{A}$ for it. Let $\mathcal{A}(I)$ be the value output by $\mathcal{A}$ given input $I$. Let $\mathrm{OPT}(I)$ be the optimal solution for $I$. $\mathcal{A}$ is an **$\alpha$-approximation algorithm** if  

$$
\forall I:\quad \frac{\mathcal{A}(I)}{\mathrm{OPT}(I)} \le \alpha
$$

For a maximization problem, $\mathcal{A}$ is an **$\alpha$-approximation algorithm** if  

$$
\forall I:\quad \frac{\mathcal{A}(I)}{\mathrm{OPT}(I)} \ge \alpha
$$

### Max-k-coverage and Set Cover Problems

Let $U = \langle n \rangle$ be a ground set of elements, and give $T = \{A_1, \ldots, a_m\}$ be a collection of subsets of $U$ with $\bigcup_{A_i \in T}A_i = U$.

**Set Cover**: Find a subcollection $S \subseteq T$ with minimum $\vert S \vert$ such that $\bigcup_{A_i \in S}A_i = U$  
**Max-k-coverage**: Find a subcollection $S \subseteq T$ with $\vert S \vert \leq k$ that maximizes $\left\vert \bigcup_{A_i \in S}A_i \right\vert$

~~They are all NP-Hard!~~

!!! normal-comment "We can describe subsets and elements with bipartite graph!"

Denote $f(S) = \left\vert \bigcup_{A_i \in S}A_i \right\vert$

```
Initialize S = ‚àÖ
repeat:
    find A ‚àà T \ S that maximizes f(S ‚à™ {A}) - f(S)
    update S = S ‚à™ {A}
until:
    f(S) = |U| (for set cover)
    |S| = k    (for max-k-coverage)
```

!!! remarks "Analysis"

    Let $S^* = \{O_1, \ldots, O_k\}$ be any collection of $k$ subsets, $S = \{A_1, \ldots, A_l\}$ be the output of the algorithm after $l$ iterations.  We gonna prove that
    
    $$
    f(S) \geq \left(1 - \left(1 - \frac{1}{k}\right)^l\right)f(S^*) \geq \left(1 - \frac{1}{\mathrm{e}}\right) f(S^*)
    $$
    
    which gives the lower bound for max-k-coverage.  
    And for $\vert S^* \vert = k$ and if we let $l = k\ln n$, we have
    
    $$
    f(S) \geq \left(1 - \left(1 - \frac{1}{k}\right)^{k \ln n}\right)f(S^*) > \left(1 - \frac{1}{\mathrm{e^{\ln n}}}\right) f(S^*) = n - 1 \Rightarrow f(S) = n
    $$
    
    which gives a $\ln n$ approximation.
    
    Proof by inductive: Let $S_t = \{A_1, \ldots, A_t\}, t = 1, 2, \ldots, l$.  
    $l = 1$, by greedy nature, $f(S_1 = \{A_1\}) \geq f(O_i)$ for all $O_i$, thus, 
    
    $$
    f(S_1) \geq \frac{1}{k}\sum_{k = 1}^{l}f\left(\{O_i\}\right) \geq \frac{1}{k}f(S^*) = \left(1 - \left(1 - \frac{1}{k}\right)^{1}\right)f(S^*)
    $$
    
    Now $S_t$ after $t$ iterations, consider $\Delta(O_i\vert S_t) = f(S_t \cup \{O_i\}) - f(S_t)$. By greedy nature, $\Delta(A_{t + 1}\vert S_t) \geq \Delta(O_i\vert S_t)$. Also we have
    
    $$
    \begin{align}
    &\Delta(A_{t + 1}\vert S_t) \geq \frac{1}{k}\sum_{k = 1}^{l}\Delta(O_i\vert S_t) \geq \frac{1}{k}\Delta(S^*\vert S_t) \\
    \Leftrightarrow& f(S_{t + 1}) - f(S_t) \geq \frac{1}{k}\left(f(S^* \cup S_t) - f(S_t)\right) \geq \frac{1}{k}\left(f(S^*) - f(S_t)\right) \\
    \Leftrightarrow& f(S_{t + 1}) \geq \frac{1}{k}f(S^*) + \left(1 - \frac{1}{k}\right)f(S_t)  \\ &= \left(1 - \left(1 - \frac{1}{k}\right)^{t + 1}\right)f(S^*)
    \end{align}
    $$

!!! remarks "Are we doing the best in poly-time?"
    we can note that all the equations above is tight (Roughly)  
    Actually, no $\displaystyle 1 - \frac{1}{\mathrm{e}} + \varepsilon$-approx algorithm unless **P = NP**

### Facility Location

#### $k$-centers

Build $k$ facilities, and minimize the maximum distance between any vertex to its closest facility. (Especially in a metric space (Â∫¶ÈáèÁ©∫Èó¥))

Input a metric space (always a undirected graph with triangle inequality) and $k$, output the $k$ center choices and $S \subseteq V$ which minimizes

$$
f(S) = \max_{v \in V} \min_{s \in S} d(S, V)
$$

it has a $2$-approx: iteratively pick the center farthest to the existing centers  

!!! remarks "Analysis"
    Let $O = \{o_1, \ldots, o_k\}$ be the optimal solution with cost $\mathrm{OPT}$  
    Let $A = \{a_1, \ldots, a_k\}$ be the algorithm‚Äôs output with cost $\mathrm{ALG}$  
    The theorem says $\mathrm{ALG} \leq 2 \cdot \mathrm{OPT}$
    
    For each $o_i$, let $X_i$ be the set of vertices closest to $o_i$ (their "min" is calculated by the dist to $o_i$). $\{X_1, \ldots, X_k\}$ is a partition of $V$. (Voronoi area)  
    Denote $d(A, v) = \min_{a \in A}d(a, v)$
    
    **Case 1.** $A \cap X_i \neq \emptyset$ for all $i$ (1), then obviously each $X_i$ contain a center in $A$. WLOG assume $a_i \in X_i$.
    { .annotate}
    
    1. Noting that **each** $X_i$ is a set.
    
    Considering any $v \in V$, assume $v \in X_i$. Then $d(a_i, v) \leq d(a_i, o_i) + d(o_i, v) \leq 2 \cdot \mathrm{OPT}$.  
    In the algorithm $v$ is assigned to $a'$, then $d(a', v) \leq d(a_i, v) \leq 2 \cdot \mathrm{OPT}$. So $\mathrm{ALG} = \min_{v \in V}d(a', v) \leq 2 \cdot \mathrm{OPT}$
    
    **Case 2** $A \cap X_i = \emptyset$ for some $i$.  

    So some $X_i$ contains two centers in $A$. Suppose $a_j, a_r \in X_i$, and $a_j$ was chosen earlier by the algorithm. So at the time $a_r$ was add to $A$, $\mathrm{ALG} \leq d(A, a_r) \leq d(a_j, a_r)$.  
    Noting that $a_j, a_r \in X_i$, $d(a_j, a_r) \leq d(a_j, o_i) + d(a_r, o_i) \leq 2 \cdot \mathrm{OPT}$  
    So we also have $\mathrm{ALG} \leq 2 \cdot \mathrm{OPT}$

    !!! normal-comment "When to get "="?"
        $V$ forms a **line** and $k = 2$, in ALG we choose the mid point and the endpoint --> $\vert V \vert / 2$, but if we choose quarter points, the OPT will be $\vert V \vert / 4$

Actually, no $(2 - \varepsilon)$-approx poly-algorithm exists.  

!!! remarks "Dominating Set Problem"
    Given an undirected graph $G = (V, E)$, a dominating set is a subset of vertices $S$ such that, for any $v \in V \backslash S$, there is a vertex $u \in S$ that is adjacent to $v$.

    **Dominating Set Problem** Given a graph $G$ and a integer $k$, decide if $G$ contains a dominating set with size $k$. It is know as an NP-Hard problem.

!!! normal-comment "Prove no $(2 - \varepsilon)$-approx poly-algorithm exists"
    If we have, denote it by $\mathcal{A}$. Given a dominating set graph $G$, for all $k$, if the output of $\mathcal{A}$ on $G$ is $1$, then $G$ has a dominating set! (Due to having a dominating set iff $\mathrm{OPT} = 1 \Leftrightarrow \mathrm{OPT} \leq \mathrm{ALG} \leq (2 - \varepsilon)\cdot\mathrm{OPT} < 2 \Leftrightarrow \mathrm{ALG} = 1$)

### Local Search: Max-Cut

Start with a solution and improve it by **local updates**

**Max Cut**: Given a undirected graph, a cut is a partition $\{A, B\}$ of $V$, the value of the cut is defined by $c(A, B) = \vert E(A, B) \vert$ (The edges between $A$ and $B$) --> Find the cut with the maximum value!

**A local search algorithm**:  
1. Start with any partition $\{A, B\}$  
2. If moving a vertex from $A$ to $B$ or from $B$ to $A$ increases $c(A, B)$, then move it  
3. Terminate until no such movement is possible

!!! remarks "Analysis"

    **Time complexity**: $O(\vert V \vert)$ for search vertex updates, and decide if the update is beneficial takes $O(\vert E \vert)$, and total number of updates is at most $O(\vert E \vert)$. Totally $O(\vert V \vert \vert E \vert^2)$

    **Approximation Guarantee**: a $0.5$-approx.

    For each $u$, at least $\displaystyle \frac{1}{2}\deg u$ incident edges in the cut (1). So
    { .annotate}

    1. Moving $u$ to the other side can not increase the num of cut 

    $$
    c(A, B) \geq \frac{1}{2}\sum_{u \in V}\frac{1}{2}\deg u = \frac{1}{2}\vert E \vert \geq \frac{1}{2}\mathrm{OPT}
    $$

    !!! normal-comment "Actually"
        $\displaystyle c(A, B) > \frac{1}{2}\vert E \vert$ also holds, and there exists a $0.878$-approximation!

