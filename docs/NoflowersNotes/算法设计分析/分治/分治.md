## Number Multiplication

- Calculate by dividing the two n-digit into two parts and recursion -- $O(n^2)$  
- Improvement;

$$
xy = ac \cdot 10^n + (ad + bc) \cdot 10^{n / 2} + bd
$$

where $ad + bc = (a + c) (b + d) - ac - bd$, using 3 times of multiplication instead of 4.  
We have time complexity (multiply times) of $\displaystyle O(3^{\log n}) \approx O(n^{1.6})$

!!! remarks "If $n$ is not 2's power?"
    Add $0$.

**Karatsuba Algorithm**

$$
T(n) = 3T\left(\frac{n}{2}\right) + O(n)
$$

> To be accurate, $3T(n / 2)$ should be $3T(n / 2 + 1)$, as $a + b, c + d$ may be of $(2n + 1)$-bit length (due to carry).

$$
\begin{aligned}
T(n) &= 3\Bigg( 3T\!\left(\frac{n}{4}\right) + c \cdot \frac{n}{2} \Bigg) + cn 
     = 3^2 T\!\left(\frac{n}{4}\right) + cn\left(1 + \frac{3}{2}\right) \\[6pt]
     &= 3^3 T\!\left(\frac{n}{2^3}\right) + cn\left(1 + \frac{3}{2} + \left(\frac{3}{2}\right)^2\right) \\[6pt]
     &= 3^4 T\!\left(\frac{n}{2^4}\right) + cn\left(1 + \frac{1}{2} + \left(\frac{3}{2}\right)^2 + \left(\frac{3}{2}\right)^3\right) \\[6pt]
     &\ \ \vdots \\[6pt]
     &= 3^{\log_2 n}T(1) 
        + cn\left(1 + \frac{1}{2} + \left(\frac{3}{2}\right)^2 + \left(\frac{3}{2}\right)^3 + \cdots 
        + \left(\frac{3}{2}\right)^{\log_2 n - 1}\right) \\[6pt]
     &= O\!\left(n^{\log_2 3}\right) + O\!\left(n^{1+\log_2 1.5}\right) 
      = O\!\left(n^{\log_2 3}\right)
\end{aligned}
$$

**Other better algorithms**

- Toom-Cook: dividing into 3 parts, reduce 9 multiplication into 5 times. --> $O(n^{1.465})$
- Schonhage-Strassen ($O(n \log n \log log n)$)... (based on FFT)

## Matrix multiplication

Directly calculate, $O(n^3)$

Strassen’s magical idea:

$$
\begin{cases}
P_{1} = A(F - H) \\
P_{2} = (A + B)H \\
P_{3} = (C + D)E \\
P_{4} = D(G - E) \\
P_{5} = (A + D)(E + H) \\
P_{6} = (B - D)(G + H) \\
P_{7} = (A - C)(E + F)
\end{cases}
$$

then 

$$
\begin{aligned}
XY &= 
\begin{pmatrix}
A & B \\
C & D
\end{pmatrix}
\begin{pmatrix}
E & F \\
G & H
\end{pmatrix} \\[6pt]
&=
\begin{pmatrix}
AE + BG & AF + BH \\
CE + DG & BF + DH
\end{pmatrix} \\[6pt]
&=
\begin{pmatrix}
P_{5} + P_{4} - P_{2} + P_{6} & P_{1} + P_{2} \\
P_{3} + P_{4} & P_{1} + P_{5} - P_{3} - P_{7}
\end{pmatrix}
\end{aligned}
$$

reducing 8 multiplication into 7.

Others:
- Strassen: $n^\omega, \omega \leq \log_2^7$
- Conjecture (猜想) $\omega = 2 + \varepsilon$ for any $\varepsilon > 0$.

## Sorting

(Omitted)

Merge Sort analysis:

$$
T(n) = 2T\left(\frac{n}{2}\right) + O(n)
$$

So 

$$
T(n) \leq 2T(n / 2) + cn \leq 2 B \cdot \frac{n}{2} \log \frac{n}{2} + cn \leq Bn\log n
$$

!!! remarks "The lower bound of compare sorting is $\Omega(n \log n)$"
    Total number of possible outputs is $3^{K(n)}$ if $K(n)$ comparisons are made.   
    The total number of possible orders is $n!$, and the algorighm needs to distinguish them. So  

    $$
    3^{K(n)} \geq n! \Rightarrow K(n) \geq \log
    $$


## Master Theorem

If $T(n) = aT(n / b) + O(n^d)$, then

$$
T(n) = 
\begin{cases}
\displaystyle O(n^d), &\quad a < b^d \\
\displaystyle O(n^{\log_ba}), &\quad a > b^d \\
\displaystyle O(n^d\log n), &\quad a = b^d
\end{cases}
$$

## Selection Problem

Find the $k$-th smallest integer among $x_1, \cdots, x_n$,  

A solution the same as quick sort: select the arbitrary item $x_0$ and divide the array into $L: x < x_0, M: x = x_0, R: x > x_0$, and recurse.  
> However, the worse case is $O(n^2)$.

**Median of the medians** (1973)

> step1. partition S into subsets with size 5 ($O(n)$)  
> step2. find the medians of the median of each subset ($O(n)$)  
> step3. fix $x_0$ to be the median of all the medians (by recursion: the $n / 2$ least) ($T(n / 5)$)

Analysis: there is about $3n / 10$ numbers larger than $x_0$ in the worst case, i.e. $\text{the-} 3 / 10 \text{-th} \leq x_0 \leq \text{the-} 7 / 10 \text{-th}$ (Why?)

So $T(n) = T(n / 5) + T(7n / 10) + O(n)$

> $T(n) --> 0.9T(n)$ after each iteration, so we guess $T(n) \leq Bn$.

$$
T(n) \leq \frac{1}{5}Bn + \frac{7}{10}Bn + Cn \leq 0.9Bn + Cn \leq Bn
$$

holds if $B \geq 10C$.

So $T(n) = O(n)$

!!! remarks "So why we divide into size 5?"

    Assume we divide into size $t$, then $\displaystyle x_0 \in \left[\frac{3t - 1}{4t}, \frac{t + 1}{4t}\right]$ (when $t$ is odd). So
    
    $$
    T(n) = T(n / t) + T\left(\frac{(3t - 1)n}{4t}\right) + O(n)
    $$
    
    $T(n) = O(n)$ iff. $\displaystyle \frac{1}{t} + \frac{(3t - 1)}{4t} \leq 1$ iff. $t \geq 5$.

    * _If $t = 3$, $T(n) = O(n \log n)$_

## Quick Sort

By _Median of the medians_, we have $O(n)$ to find the median number. So

$$
T(n) = 2T(n / 2) + O(n) \Rightarrow T(n) = O(n \log n)
$$

> However, it is low in practice! (_Median of the medians_ is low due to the large constant $B$!)

**Choose the pivot item by random**:

let $a_i$: the $i$-th smallest number in the array, $\displaystyle X_{ij} =\begin{cases}1, & a_i, a_j \text{ have been compared} \\ 0, &\text{otherwise}\end{cases}$, and $X: \text{Total compare times}$.  

So we have $\mathbb{E}(X) = \mathbb{E}\sum X_{ij} = \sum P(X_{ij} = 1)$.

$X_{ij} = 0$ iff. $a_i, a_j$ have been divided into 2 different groups. Noting that all the number will be chosen once during the whole algorithm, and we only pay attention to the first number chosen between $a_i, a_j$. So $\displaystyle P(X_{ij} = 1) = \frac{2}{j - i + 1}$ (they are not divided at first).

So $\displaystyle \mathbb{E}(X) = \sum \frac{2}{j - i + 1} = \Theta (n \log n)$

!!! remarks "The derivation"
    
    Let $d = j - i$

    $$
    \begin{align}
    \mathbb{E}(X) =& \sum_{d = 1}^{n - 1}\frac{2(n - d)}{d + 1} \\
    =& (2n + 2)\sum_{d = 1}^{n - 1}\frac{1}{d + 1} - 2(n - 1) \\
     \approx& (2n + 2)\log n - 2(n - 1) = \Theta (n \log n)
    \end{align}
    $$

## Closest Pairs

Find the closest dot pair on the 2-D plane.

## Polynomial Multiplication -- FFT

Let $p(x) = a_0 + \ldots + a_{d - 1}x^{d - 1}, q(x) = b_0 + \ldots + b_{d - 1}x^{d - 1}$.

Solution 1: Adapting Karatsuba Algorithm --> $O(d^{\log_2 3})$

A $O(d \log d)$ solution: FFT

![img.png](img.png)

**step1**. Choose $2d - 1$ distinct numbers $a_0, \cdots, a_{2d - 2}$, and compute $p(a_i), q(a_i)$

We can view polynomial evaluation as a matrix–vector multiplication:

$$
\begin{pmatrix}p(x_0) \\ \vdots \\ p(x_{d - 1})\end{pmatrix}
= \begin{pmatrix}1 & \cdots & x^{d - 1} \\ \vdots & \ddots & \vdots \\ x^{d - 1} & \cdots & x^{(d - 1)(d - 1)}\end{pmatrix}\begin{pmatrix}a_0 \\ \vdots \\ a_{d - 1}\end{pmatrix}
$$

Directly compute every $p(a_i), q(a_i)$: $O(d^2)$ --> bad!  
However, computing each $p(a_i)$ requires $O(d)$ time!  

Noting that if we let

$$
\begin{align}
p_e(x) &= a_0 + a_2 x + \cdots + a_{d - 2}x^{d/2 - 1} \\
p_o(x) &= a_1 + a_3x + \cdots + a_{d - 1}x^{d / 2 - 1}
\end{align}
$$

then 

$$
p(x) = p_e(x^2) + xp_o(x^2)
$$
 
Let $a_1 = - a_0, a_3 = -a_2, \cdots$ 

$$
\begin{align}
p(a_1) &= p_e(a_0^2) - a_0p_o(a_0^2) \\
p(a_0) &= p_e(a_0^2) + a_0p_o(a_0^2)
\end{align}
$$

By this we can just compute half of $p(a_i)$. So with the same task size, we reduce degree $d$ to $d / 2$.

Then recursively compute $p_e$ and $p_o$, total time complexity $O(d \log d)$.

To ensure the recurse is continuous, in practice we use the unit roots: $\displaystyle \omega = \mathrm{e}^{\frac{2\pi}{d}i}$

```
FFT(p, w):
    If w = 1: return p(1)
    Define p_e(x) and p_o(x)
    
    (p_e(w^0), p_e(w^2), ..., p_e(w^{D - 2})) = FFT(p_e, w^2)
    (p_o(w^0), p_o(w^2), ..., p_o(w^{D - 2})) = FFT(p_o, w^2)
    
    For t = 0, 1, ..., D - 1:
        p(w^t) = p_e(w^{2t}) + w^t p_o(w^{2t})
    Return (p(w^0), ..., p(w^{D - 1}))
```

**step2**. Compute $r(a_i) = p(a_i)q(a_i)$, $O(d)$.  

**step3**. Compute $r(x)$.  

$$
\begin{pmatrix}
r(1)\\
r(\omega)\\
r(\omega^{2})\\
\vdots\\
r(\omega^{d-1})
\end{pmatrix}
=
\underbrace{\begin{pmatrix}
1 & 1 & 1 & \cdots & 1\\
1 & \omega & \omega^{2} & \cdots & \omega^{d-1}\\
1 & \omega^{2} & \omega^{4} & \cdots & \omega^{2(d-1)}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
1 & \omega^{d-1} & \omega^{2(d-1)} & \cdots & \omega^{(d-1)(d-1)}
\end{pmatrix}}_{A}
\begin{pmatrix}
c_0\\
c_1\\
c_2\\
\vdots\\
c_{d-1}
\end{pmatrix}
$$

And due to $\displaystyle \frac{1}{\sqrt{d}}A$ is orthonormal, $\displaystyle \left(\frac{1}{\sqrt{d}}A\right)^{-1} = \left(\frac{1}{\sqrt{d}}A\right)^* = \overline{\left(\frac{1}{\sqrt{d}}A\right)^T}$.  
So $\displaystyle A(\omega)^{-1} = \frac{1}{d}A(\omega)^*$. Noting:

$$
\left(A(\omega)^{-1}\right)_{i, j} = \frac{1}{d} \overline{\left(A(\omega)\right)_{j, i}} = \frac{1}{d}\left(\omega^{-1}\right)^{(i - 1)(j - 1)}
$$

So $\displaystyle A(\omega)^{-1} = \frac{1}{D}\cdot A\left(\omega^{-1}\right)$

$$
\begin{pmatrix}
c_0\\
c_1\\
c_2\\
\vdots\\
c_{d-1}
\end{pmatrix}
=
\frac{1}{D} \cdot A(\omega^{-1}) \cdot
\begin{pmatrix}
r(1)\\
r(\omega)\\
r(\omega^{2})\\
\vdots\\
r(\omega^{d-1})
\end{pmatrix}
$$

It is same as compute $\displaystyle s\left(x\right) = \frac{r(1)}{d} + \frac{r(\omega)}{d}x + \ldots + \frac{r(\omega^{d - 1})}{d}x^{d - 1}$ with $x = \omega^{-1}, \ldots, \omega^{-(d - 1)}$. So we can apply function `FFT` in $O(d \log d)$!

