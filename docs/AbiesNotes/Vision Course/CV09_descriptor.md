## 基本想法

以 3\*3 的尺度为例。

一个简单的想法：转化为**向量匹配**

- 想法 1：将 9 个像素编号，排成九维向量进行匹配。但要求不能有旋转等。
- 改进 1：求相邻像素的差分，排成六维向量。这样允许光照强度变化。

为了包含几何扭曲，用**颜色直方图**

- 想法 2（color histogram）：提取窗口中的颜色，做成颜色直方图。但这样描述性低。
- 改进 2（spatial histograms）：将窗口分为几个格子，每个格子分别做颜色直方图。但是这样不能有旋转。
- 改进 3（orienrarion normalization）：绘制梯度的直方图（梯度反映方向），先根据梯度旋转到标准位置，再分割、做颜色直方图。

## 几种特征描述子

### SIFT

SIFT（Scale Invariant Feature Transform）从图像中提取稳定、可匹配的关键点（features），用于图像匹配、目标识别、三维重建等。

Descriptor 流程：

1. 在特征点区域采样 16\*16 的点；
2. 对每个采样点，计算边界的方向（即梯度的反方向）；
3. 去掉边界中过小的值；
4. 0~360 度等分为 8 份，建立直方图，剩下的 edge 中每个点对 8 个方向投票（可能是加权投票）；
5. 具体实现时先划分为 16 个 4\*4 的格子，每个格子建立八维直方图，最后再整合。

SIFT 表现好，设计上能处理视角变化、平面内旋转等，实际上还能容忍平面外旋转、光照等变化。

### SURF

SURF（Speeded-Up Robust Features）的目标是在保持与 SIFT 相似鲁棒性的同时，显著加快特征提取速度。

流程：

1. **构建尺度空间**（Scale-space）：SIFT 通过不断模糊图像（高斯金字塔）实现多尺度分析；SURF 则固定图像，用不同大小的滤波器卷积代替缩放。
2. **关键点检测**（Keypoint Detection）：使用 Hessian 矩阵的行列式（determinant of Hessian）作为特征强度，取其行列式 (|H|) 的极值点作为候选关键点。
   - SURF 用简单的 box filter（盒式滤波器）近似卷积运算，这些滤波器的系数只有 1 和 -1，可用**积分图像**高效计算。
3. **方向分配**（Orientation Assignment）：在关键点邻域内计算 Haar 小波响应（Haar wavelet responses）。根据主方向分布，给关键点分配一个主方向，使其旋转不变。
4. **特征描述符生成**（Descriptor）：在关键点周围取一个固定大小的邻域（通常是 20×20 像素），分成 4×4 个子区块。每个区块中计算 Haar 小波在 x 和 y 方向的响应统计量。将这些统计量拼接为一个 64 维向量（4×4×4 = 64）。

**积分图像（Integral Image）**：每个像素的位置放图像左上角到当前位置的像素之和。要得到某一块的和，只需要 integral image 相应位置的值简单 加减（相当于二维前缀和）。

### BRIEF

BRIEF (Binary Robust Independent Elementary Features)是一种用二进制（0/1）来表示图像局部特征的描述子，用简单的比较代替复杂的梯度统计，实现超快特征匹配。

流程：

1. 先对图像高斯滤波；
2. 对相邻的像素(x,y)，如果 x 的值更小，则 r(x;y)为 1，否则为 0；
3. 将所有比较结果依次排列成一个二进制串，计算 Hamming distance。由于是二进制串，可以用 XOR（异或）运算 + 位计数 实现，速度极快。

优点：

- 极快（用逻辑运算代替浮点计算）
- 占用内存少（256 bits = 32 bytes）
- 匹配速度快（适合实时应用）

缺点：

- 对旋转不敏感（即旋转后匹配度下降）
- 对尺度变化不鲁棒（需与其他算法结合，如 ORB）

### ORB

ORB 是 FAST 和 BRIEF 的结合。

在 FAST 下计算 orientation，在 BRIEF 之前先根据角度旋转图像。

### GIST

GIST（Global Image Descriptor）基于心理学实验，人类在识别场景时，不需要识别所有细节，而是通过“整体印象（Gist）”快速判断图像的类别。

流程：

1. **预处理**（Preprocessing）：将输入图像转换为灰度图，进行归一化和滤波，以消除亮度或对比度的影响。
2. **卷积特征提取**（Filter Bank Convolution）：使用一组 Gabor 滤波器进行卷积。每个滤波器代表不同的方向和尺度，可以捕捉不同方向的纹理信息。
3. **空间划分与统计**（Spatial Pooling）：将卷积结果划分为固定网格（例如 4\*4）。在每个小格中，计算滤波响应的平均值。这样既保留了整体布局，又减少了特征维度。
4. **特征拼接**（Feature Concatenation）：将所有滤波器、所有格子的平均值连接成一个长向量，得到整张图像的 GIST 描述子。

**Gabor filter**：待补充。

### HOG

HOG（Histogram of Oriented Gradients，方向梯度直方图）是一种用于物体检测（特别是行人检测）的方法，基于图像局部区域内的梯度信息提取特征，常用于视觉识别任务。

流程：

1. **计算梯度**：对输入图像中的每个像素，计算水平方向和垂直方向上的梯度（通常使用 Sobel 算子），得到图像中每个像素的梯度方向和梯度幅值。
2. **分区域（Cells**）：将图像划分为若干小的网格区域，称为 Cells，每个 Cell 通常是一个 8x8 或 16x16 的像素块。对每个 Cell，计算其内部的梯度方向直方图。
3. **计算方向直方图**：在每个 Cell 内，统计该区域内每个像素的梯度方向，并根据梯度的方向将其分到指定的角度区间内（通常分为 9 个方向，范围是 0~180 度）。每个 Cell 会生成一个 9 维的直方图向量，其中每个维度代表一个方向的梯度强度。
4. **块归一化（Block Normalization）**：将若干个相邻的 Cells 组成一个 Block（通常 4 个 Cell 组成一个 Block），然后对每个 Block 中的梯度直方图进行归一化处理。归一化有助于消除光照变化和对比度差异的影响，增强模型的鲁棒性。
5. **生成 HOG 特征向量**：将所有 Block 的归一化后的直方图串联起来，形成一个大的特征向量，这就是图像的 HOG 特征描述子。
6. **分类器训练**：使用支持向量机（SVM）等分类器，基于 HOG 特征训练模型。通过将 HOG 特征向量输入到分类器，模型可以判断图像中是否包含目标物体（例如，是否有人）。

## 特征匹配

对每个特征点定义距离。如果两张图中特征点距离小于阈值，则这两个点匹配。  
距离一般定义为$L_2$ distance（欧几里得距离）、Hamming distance、夹角等。

图片中有重复性结构时，会相互干扰。  
解决：同时考虑最近和第二近的特征点，判断两者的差距是不是足够大。如果两者差距不大，则匹配的唯一性低。  
阈值的大小决定匹配的严格性。需要在 recall 和 precision 中 trade-off。
